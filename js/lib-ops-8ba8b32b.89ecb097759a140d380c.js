/*! For license information please see lib-ops-8ba8b32b.89ecb097759a140d380c.js.LICENSE.txt */
"use strict";(self.webpackChunktheremin=self.webpackChunktheremin||[]).push([[715],{748:(e,n,t)=>{t.d(n,{$:()=>xn,A:()=>gn,B:()=>we,C:()=>hn,D:()=>un,E:()=>ln,F:()=>sn,G:()=>rn,H:()=>en,I:()=>nn,J:()=>_e,K:()=>pe,L:()=>ke,M:()=>Ee,N:()=>ue,O:()=>ae,P:()=>ne,Q:()=>B,R:()=>V,S:()=>A,T:()=>$,U:()=>v,V:()=>w,W:()=>_,X:()=>q,Y:()=>m,Z:()=>f,_:()=>d,a:()=>vn,a$:()=>le,a0:()=>Nn,a1:()=>Z,a2:()=>Me,a3:()=>S,a4:()=>ze,a5:()=>De,a6:()=>y,a7:()=>H,a8:()=>Y,a9:()=>O,aA:()=>Ve,aB:()=>Q,aC:()=>On,aD:()=>l,aE:()=>ee,aF:()=>i,aG:()=>zn,aH:()=>ye,aI:()=>cn,aJ:()=>ge,aK:()=>M,aL:()=>L,aM:()=>z,aN:()=>G,aO:()=>x,aP:()=>k,aQ:()=>E,aR:()=>g,aS:()=>We,aT:()=>Ce,aU:()=>ve,aV:()=>In,aW:()=>Mn,aX:()=>mn,aY:()=>se,aZ:()=>qn,a_:()=>tn,aa:()=>Fn,ab:()=>Wn,ac:()=>R,ad:()=>P,ae:()=>J,af:()=>yn,ag:()=>Xe,ah:()=>Je,ai:()=>Be,aj:()=>Ae,ak:()=>u,al:()=>He,am:()=>be,an:()=>ie,ao:()=>on,ap:()=>Kn,aq:()=>Sn,ar:()=>$n,as:()=>j,at:()=>Te,au:()=>Ke,av:()=>Ne,aw:()=>me,ax:()=>fe,ay:()=>ce,az:()=>he,b:()=>h,b0:()=>dt,b1:()=>fn,b2:()=>bn,b3:()=>dn,b4:()=>pn,b5:()=>ft,b6:()=>I,b7:()=>C,b8:()=>U,b9:()=>D,ba:()=>Le,bb:()=>Ge,bc:()=>Pe,bd:()=>qe,be:()=>Qe,bf:()=>Ze,bg:()=>xe,c:()=>K,d:()=>p,e:()=>re,f:()=>te,g:()=>$e,h:()=>N,i:()=>pt,j:()=>W,k:()=>En,l:()=>Re,m:()=>Ie,n:()=>c,o:()=>X,p:()=>Ue,q:()=>Fe,r:()=>b,s:()=>kn,t:()=>wn,u:()=>de,v:()=>Ye,w:()=>an,x:()=>_n,y:()=>T,z:()=>Oe}),t(5389),t(3807);var r=t(198),a=t(3077),s=t(9166),o=t(3687);const i=(0,r.o)({matMul_:function(e,n,t=!1,a=!1){let s=(0,r.q)(e,"a","matMul"),o=(0,r.q)(n,"b","matMul");[s,o]=(0,r.u)(s,o);const i={a:s,b:o},u={transposeA:t,transposeB:a};return r.E.runKernel(r.B,i,u)}}),u=(0,r.o)({oneHot_:function(e,n,t=1,a=0){if(n<2)throw new Error(`Error in oneHot: depth must be >=2, but it is ${n}`);const s={indices:(0,r.q)(e,"indices","oneHot","int32")},o={depth:n,onValue:t,offValue:a};return r.E.runKernel(r.O,s,o)}}),l=(0,r.o)({transpose_:function(e,n){const t=(0,r.q)(e,"x","transpose");if(null==n&&(n=t.shape.map(((e,n)=>n)).reverse()),(0,a.a)(t.rank===n.length,(()=>`Error in transpose: rank of input ${t.rank} must match length of perm ${n}.`)),n.forEach((e=>{(0,a.a)(e>=0&&e<t.rank,(()=>"All entries in 'perm' must be between 0 and "+(t.rank-1)+` but got ${n}`))})),t.rank<=1)return t.clone();const s={x:t},o={perm:n};return r.E.runKernel(r.v,s,o)}}),h=(0,r.o)({add_:function(e,n){let t=(0,r.q)(e,"a","add"),a=(0,r.q)(n,"b","add");[t,a]=(0,r.u)(t,a);const s={a:t,b:a};return r.E.runKernel(r.A,s)}}),c=(0,r.o)({floorDiv_:function(e,n){let t=(0,r.q)(e,"a","floorDiv"),a=(0,r.q)(n,"b","floorDiv");[t,a]=(0,r.u)(t,a);const s={a:t,b:a};return r.E.runKernel(r.F,s)}}),p=(0,r.o)({div_:function(e,n){let t=(0,r.q)(e,"a","div"),a=(0,r.q)(n,"b","div");if([t,a]=(0,r.u)(t,a),"int32"===t.dtype&&"int32"===a.dtype)return c(t,a);const s={a:t,b:a};return r.E.runKernel(r.R,s,{})}}),d=(0,r.o)({abs_:function(e){const n=(0,r.q)(e,"x","abs");if("complex64"===n.dtype){const e={x:n};return r.E.runKernel(r.C,e)}{const e={x:n};return r.E.runKernel(r.w,e)}}}),f=(0,r.o)({acos_:function(e){const n={x:(0,r.q)(e,"x","acos")};return r.E.runKernel(r.x,n)}}),m=(0,r.o)({acosh_:function(e){const n={x:(0,r.q)(e,"x","acosh")};return r.E.runKernel(r.y,n)}}),b=(0,r.o)({addN_:function(e){(0,a.a)(Array.isArray(e),(()=>"The argument passed to tf.addN() must be a list of tensors")),(0,a.a)(e.length>=1,(()=>`Must pass at least one tensor to tf.addN(), but got ${e.length}`));const n=e.map(((e,n)=>(0,r.q)(e,`tensors${n}`,"addN"))),t=n[0];n.forEach((e=>{if(e.dtype!==t.dtype)throw new Error("All tensors passed to tf.addN() must have the same dtype")})),n.forEach((e=>{if(!(0,a.b)(e.shape,t.shape))throw new Error("All tensors passed to tf.addN() must have the same shape")}));const s=n;return r.E.runKernel(r.z,s)}}),g=(0,r.o)({all_:function(e,n=null,t=!1){const a={x:(0,r.q)(e,"x","all","bool")},s={axis:n,keepDims:t};return r.E.runKernel(r.D,a,s)}}),E=(0,r.o)({any_:function(e,n=null,t=!1){const a={x:(0,r.q)(e,"x","any","bool")},s={axis:n,keepDims:t};return r.E.runKernel(r.G,a,s)}}),k=(0,r.o)({argMax_:function(e,n=0){const t={x:(0,r.q)(e,"x","argMax")},a={axis:n};return r.E.runKernel(r.H,t,a)}}),x=(0,r.o)({argMin_:function(e,n=0){const t={x:(0,r.q)(e,"x","argMin")},a={axis:n};return r.E.runKernel(r.I,t,a)}}),q=(0,r.o)({asin_:function(e){const n={x:(0,r.q)(e,"x","asin")};return r.E.runKernel(r.J,n)}}),_=(0,r.o)({asinh_:function(e){const n={x:(0,r.q)(e,"x","asinh")};return r.E.runKernel(r.K,n)}}),w=(0,r.o)({atan_:function(e){const n={x:(0,r.q)(e,"x","atan")};return r.E.runKernel(r.L,n)}}),v=(0,r.o)({atan2_:function(e,n){let t=(0,r.q)(e,"a","atan2"),a=(0,r.q)(n,"b","atan2");[t,a]=(0,r.u)(t,a);const s={a:t,b:a};return r.E.runKernel(r.M,s)}}),$=(0,r.o)({atanh_:function(e){const n={x:(0,r.q)(e,"x","atanh")};return r.E.runKernel(r.N,n)}}),y=(0,r.o)({avgPool_:function(e,n,t,s,o){const i=(0,r.q)(e,"x","avgPool","float32");(0,a.a)((0,r.P)(t,1),(()=>`Error in avgPool: Either strides or dilations must be 1. Got strides ${t} and dilations '1'`));let u=i,l=!1;3===i.rank&&(l=!0,u=(0,r.r)(i,[1,i.shape[0],i.shape[1],i.shape[2]])),(0,a.a)(4===u.rank,(()=>`Error in avgPool: x must be rank 4 but got rank ${u.rank}.`)),(0,r.Q)("avgPool",s,o);const h={x:u},c={filterSize:n,strides:t,pad:s,dimRoundingMode:o};let p=r.E.runKernel(r.S,h,c);return p=(0,r.c)(p,i.dtype),l?(0,r.r)(p,[p.shape[1],p.shape[2],p.shape[3]]):p}}),S=(0,r.o)({avgPool3d_:function(e,n,t,s,o,i="NDHWC"){const u=(0,r.q)(e,"x","avgPool3d","float32");let l=u,h=!1;4===u.rank&&(h=!0,l=(0,r.r)(u,[1,u.shape[0],u.shape[1],u.shape[2],u.shape[3]])),(0,a.a)(5===l.rank,(()=>`Error in avgPool3d: x must be rank 5 but got rank ${l.rank}.`)),(0,a.a)("NDHWC"===i,(()=>`Error in avgPool3d: Only NDHWC is currently supported, but got dataFormat of ${i}`)),(0,r.Q)("avgPool3d",s,o);const c={x:l},p={filterSize:n,strides:t,pad:s,dimRoundingMode:o,dataFormat:i};let d=r.E.runKernel(r.U,c,p);return d=(0,r.c)(d,l.dtype),h?(0,r.r)(d,[d.shape[1],d.shape[2],d.shape[3],d.shape[4]]):d}}),N=(0,r.o)({concat_:function(e,n=0){(0,a.a)(e.length>=1,(()=>"Pass at least one tensor to concat"));const t=(0,r.V)(e,"tensors","concat","string_or_numeric");if("complex64"===t[0].dtype&&t.forEach((e=>{if("complex64"!==e.dtype)throw new Error(`Cannot concatenate complex64 tensors with a tensor\n          with dtype ${e.dtype}. `)})),1===t.length)return(0,r.a)(t[0]);const s=t,o={axis:n};return r.E.runKernel(r.W,s,o)}}),K=(0,r.o)({slice_:function(e,n,t){const a=(0,r.q)(e,"x","slice","string_or_numeric");if(0===a.rank)throw new Error("Slicing scalar is not possible");const s={x:a},o={begin:n,size:t};return r.E.runKernel(r.X,s,o)}}),T=(0,r.o)({tanh_:function(e){const n={x:(0,r.q)(e,"x","tanh","float32")};return r.E.runKernel(r.Y,n)}}),D=(0,r.o)({batchToSpaceND_:function(e,n,t){const s=(0,r.q)(e,"x","batchToSpaceND"),o=n.reduce(((e,n)=>e*n));(0,a.a)(s.rank>=1+n.length,(()=>`input rank is ${s.rank} but should be > than blockShape.length ${n.length}`)),(0,a.a)(t.length===n.length,(()=>`crops.length is ${t.length} but should be equal to blockShape.length  ${n.length}`)),(0,a.a)(s.shape[0]%o==0,(()=>`input tensor batch is ${s.shape[0]} but is not divisible by the product of the elements of blockShape ${n.join(" * ")} === ${o}`));const i={x:s},u={blockShape:n,crops:t};return r.E.runKernel(r.Z,i,u)}}),M=(0,r.o)({batchNorm_:function(e,n,t,s,o,i){null==i&&(i=.001);const u=(0,r.q)(e,"x","batchNorm"),l=(0,r.q)(n,"mean","batchNorm"),h=(0,r.q)(t,"variance","batchNorm");let c,p;null!=o&&(c=(0,r.q)(o,"scale","batchNorm")),null!=s&&(p=(0,r.q)(s,"offset","batchNorm")),(0,a.a)(l.rank===h.rank,(()=>"Batch normalization gradient requires mean and variance to have equal ranks.")),(0,a.a)(null==p||l.rank===p.rank,(()=>"Batch normalization gradient requires mean and offset to have equal ranks.")),(0,a.a)(null==c||l.rank===c.rank,(()=>"Batch normalization gradient requires mean and scale to have equal ranks."));const d=function(e){let n;return n=0===e.rank||1===e.rank?(0,r.r)(e,[1,1,1,e.size]):2===e.rank?(0,r.r)(e,[1,1,e.shape[0],e.shape[1]]):3===e.rank?(0,r.r)(e,[1,e.shape[0],e.shape[1],e.shape[2]]):e,n}(u),f={x:d,scale:c,offset:p,mean:l,variance:h},m={varianceEpsilon:i},b=r.E.runKernel(r._,f,m);return(0,r.r)(b,u.shape)}}),z=(0,r.o)({bincount_:function(e,n,t){const s=(0,r.q)(e,"x","bincount"),o=(0,r.q)(n,"weights","bincount");(0,a.a)("int32"===s.dtype,(()=>`Error in bincount: input dtype must be int32, but got ${s.dtype}`)),(0,a.a)(t>=0,(()=>`size must be non-negative, but got ${t}.`)),(0,a.a)(o.size===s.size||0===o.size,(()=>`Error in bincount: weights must have the same size as input or0-length, but got input shape: ${s.shape}, weights shape: ${o.shape}.`));const i={x:s,weights:o},u={size:t};return r.E.runKernel(r.$,i,u)}}),I=(0,r.o)({broadcastArgs_:function(e,n){const t=(0,r.q)(e,"s0","broadcastArgs","int32"),a=(0,r.q)(n,"s1","broadcastArgs","int32");if(1!==t.rank)throw new Error(`broadcastArgs(): first input must be a vector (rank=1). Has rank ${t.rank}`);if(1!==a.rank)throw new Error(`broadcastArgs(): second input must be a vector (rank=1). Has rank ${a.rank}`);const s={s0:t,s1:a};return r.E.runKernel(r.a0,s)}}),C=(0,r.o)({broadcastTo_:function(e,n){let t=(0,r.q)(e,"broadcastTo","x");const a=t.shape;if(n.some((e=>!(e>0)||e%1!=0)))throw new Error(`broadcastTo(): Invalid broadcast shape [${n}].`);if(n.length<t.rank)throw new Error(`broadcastTo(): shape.length=${n.length} < input.rank=${t.rank}.`);if(n.length>t.rank){const e=t.shape.slice();for(;e.length<n.length;)e.unshift(1);t=(0,r.r)(t,e)}const s=t.shape,o=Array.from(n);for(let e=n.length-1;e>=0;e--)if(s[e]===n[e])o[e]=1;else if(1!==t.shape[e])throw new Error(`broadcastTo(): [${a}] cannot be broadcast to [${n}].`);if(0===o.map(((e,n)=>e>1?n:-1)).filter((e=>e>=0)).length)return(0,r.a)(t);const i={x:t},u={reps:o};return r.E.runKernel(r.a1,i,u)}}),A=(0,r.o)({ceil_:function(e){const n={x:(0,r.q)(e,"x","ceil","float32")};return r.E.runKernel(r.a2,n)}}),W=(0,r.o)({clipByValue_:function(e,n,t){const s=(0,r.q)(e,"x","clipByValue");(0,a.a)(n<=t,(()=>`Error in clip: min (${n}) must be less than or equal to max (${t}).`));const o={x:s},i={clipValueMin:n,clipValueMax:t};return r.E.runKernel(r.a3,o,i)}}),R=(0,r.o)({conv2d_:function(e,n,t,s,o="NHWC",i=[1,1],u){const l=(0,r.q)(e,"x","conv2d","float32"),h=(0,r.q)(n,"filter","conv2d","float32");let c=l,p=!1;3===l.rank&&(p=!0,c=(0,r.r)(l,[1,l.shape[0],l.shape[1],l.shape[2]])),(0,a.a)(4===c.rank,(()=>`Error in conv2d: input must be rank 4, but got rank ${c.rank}.`)),(0,a.a)(4===h.rank,(()=>`Error in conv2d: filter must be rank 4, but got rank ${h.rank}.`)),(0,r.Q)("conv2d",s,u);const d="NHWC"===o?c.shape[3]:c.shape[1];(0,a.a)(d===h.shape[2],(()=>`Error in conv2d: depth of input (${d}) must match input depth for filter ${h.shape[2]}.`)),(0,a.a)((0,r.P)(t,i),(()=>`Error in conv2D: Either strides or dilations must be 1. Got strides ${t} and dilations '${i}'`));const f={x:c,filter:h},m={strides:t,pad:s,dataFormat:o,dilations:i,dimRoundingMode:u},b=r.E.runKernel(r.a4,f,m);return p?(0,r.r)(b,[b.shape[1],b.shape[2],b.shape[3]]):b}}),P=(0,r.o)({conv1d_:function(e,n,t,s,o="NWC",i=1,u){const l=(0,r.q)(e,"x","conv1d"),h=(0,r.q)(n,"filter","conv1d");let c=l,p=!1;2===l.rank&&(p=!0,c=(0,r.r)(l,[1,l.shape[0],l.shape[1]])),(0,a.a)(3===c.rank,(()=>`Error in conv1d: input must be rank 3, but got rank ${c.rank}.`)),(0,a.a)(3===h.rank,(()=>`Error in conv1d: filter must be rank 3, but got rank ${h.rank}.`)),(0,r.Q)("conv1d",s,u),(0,a.a)(c.shape[2]===h.shape[1],(()=>`Error in conv1d: depth of input (${c.shape[2]}) must match input depth for filter ${h.shape[1]}.`)),(0,a.a)((0,r.P)(t,i),(()=>`Error in conv1D: Either stride or dilation must be 1. Got stride ${t} and dilation '${i}'`)),(0,a.a)("NWC"===o,(()=>`Error in conv1d: got dataFormat of ${o} but only NWC is currently supported.`));const d=(0,r.r)(h,[1,h.shape[0],h.shape[1],h.shape[2]]),f=(0,r.r)(c,[c.shape[0],1,c.shape[1],c.shape[2]]),m=R(f,d,[1,t],s,"NHWC",[1,i],u);return p?(0,r.r)(m,[m.shape[2],m.shape[3]]):(0,r.r)(m,[m.shape[0],m.shape[2],m.shape[3]])}}),F=(0,r.o)({conv2DBackpropInput_:function(e,n,t,s,o,i="NHWC",u){(0,a.a)(e.length===n.rank,(()=>`Length of inShape (${e.length}) and rank of dy (${n.rank}) must match`));let l=e,h=n,c=!1;3===n.rank&&(c=!0,h=(0,r.r)(n,[1,n.shape[0],n.shape[1],n.shape[2]]),l=[1,e[0],e[1],e[2]]),(0,a.a)(4===l.length,(()=>`Error in conv2dDerInput: inShape must be length 4, but got length ${l.length}.`)),(0,a.a)(4===h.rank,(()=>`Error in conv2dDerInput: dy must be rank 4, but got rank ${h.rank}`)),(0,a.a)(4===t.rank,(()=>`Error in conv2dDerInput: filter must be rank 4, but got rank ${t.rank}`));const p="NHWC"===i?l[3]:l[1],d="NHWC"===i?h.shape[3]:h.shape[1];(0,a.a)(p===t.shape[2],(()=>`Error in conv2dDerInput: depth of input (${p}) must match input depth for filter ${t.shape[2]}.`)),(0,a.a)(d===t.shape[3],(()=>`Error in conv2dDerInput: depth of output (${d}) must match output depth for filter ${t.shape[3]}.`)),(0,r.Q)("conv2dDerInput",o,u);const f={dy:h,filter:t},m={strides:s,pad:o,dataFormat:i,dimRoundingMode:u,inputShape:l},b=r.E.runKernel(r.a5,f,m);return c?(0,r.r)(b,[b.shape[1],b.shape[2],b.shape[3]]):b}}),O=(0,r.o)({conv2dTranspose_:function(e,n,t,a,s,o){const i=(0,r.q)(e,"x","conv2dTranspose"),u=(0,r.q)(n,"filter","conv2dTranspose");return F(t,i,u,a,s,"NHWC",o)}}),H=(0,r.o)({conv3d_:function(e,n,t,s,o="NDHWC",i=[1,1,1]){const u=(0,r.q)(e,"x","conv3d"),l=(0,r.q)(n,"filter","conv3d");let h=u,c=!1;4===u.rank&&(c=!0,h=(0,r.r)(u,[1,u.shape[0],u.shape[1],u.shape[2],u.shape[3]])),(0,a.a)(5===h.rank,(()=>`Error in conv3d: input must be rank 5, but got rank ${h.rank}.`)),(0,a.a)(5===l.rank,(()=>`Error in conv3d: filter must be rank 5, but got rank ${l.rank}.`)),(0,a.a)(h.shape[4]===l.shape[3],(()=>`Error in conv3d: depth of input (${h.shape[4]}) must match input depth for filter ${l.shape[3]}.`)),(0,a.a)((0,r.P)(t,i),(()=>`Error in conv3D: Either strides or dilations must be 1. Got strides ${t} and dilations '${i}'`)),(0,a.a)("NDHWC"===o,(()=>`Error in conv3d: got dataFormat of ${o} but only NDHWC is currently supported.`));const p={x:h,filter:l},d={strides:t,pad:s,dataFormat:o,dilations:i},f=r.E.runKernel(r.a6,p,d);return c?(0,r.r)(f,[f.shape[1],f.shape[2],f.shape[3],f.shape[4]]):f}}),V=(0,r.o)({cos_:function(e){const n={x:(0,r.q)(e,"x","cos","float32")};return r.E.runKernel(r.a7,n)}}),B=(0,r.o)({cosh_:function(e){const n={x:(0,r.q)(e,"x","cosh","float32")};return r.E.runKernel(r.a8,n)}}),G=(0,r.o)({cumsum_:function(e,n=0,t=!1,a=!1){const s={x:(0,r.q)(e,"x","cumsum")},o={axis:n,exclusive:t,reverse:a};return r.E.runKernel(r.a9,s,o)}}),L=(0,r.o)({denseBincount_:function(e,n,t,s=!1){const o=(0,r.q)(e,"x","denseBincount"),i=(0,r.q)(n,"weights","denseBincount");(0,a.a)("int32"===o.dtype,(()=>`Error in denseBincount: input dtype must be int32, but got ${o.dtype}`)),(0,a.a)(o.rank<=2,(()=>`Error in denseBincount: input must be at most rank 2, but got rank ${o.rank}.`)),(0,a.a)(t>=0,(()=>`size must be non-negative, but got ${t}.`)),(0,a.a)(i.size===o.size||0===i.size,(()=>`Error in denseBincount: weights must have the same shape as x or 0-length, but got x shape: ${o.shape}, weights shape: ${i.shape}.`));const u={x:o,weights:i},l={size:t,binaryOutput:s};return r.E.runKernel(r.aa,u,l)}}),U=(0,r.o)({depthToSpace_:function(e,n,t="NHWC"){const s=(0,r.q)(e,"x","depthToSpace","float32"),o="NHWC"===t?s.shape[1]:s.shape[2],i="NHWC"===t?s.shape[2]:s.shape[3],u="NHWC"===t?s.shape[3]:s.shape[1];(0,a.a)(n>1,(()=>`blockSize should be > 1 for depthToSpace, but was: ${n}`)),(0,a.a)(o*n>=0,(()=>`Negative dimension size caused by overflow when multiplying\n    ${o} and ${n}  for depthToSpace with input shape\n    ${s.shape}`)),(0,a.a)(i*n>=0,(()=>`Negative dimension size caused by overflow when multiplying\n    ${i} and ${n} for depthToSpace with input shape\n        ${s.shape}`)),(0,a.a)(u%(n*n)==0,(()=>`Dimension size must be evenly divisible by ${n*n} but is ${u} for depthToSpace with input shape ${s.shape}`));const l={x:s},h={blockSize:n,dataFormat:t};return r.E.runKernel(r.ab,l,h)}}),Y=(0,r.o)({depthwiseConv2d_:function(e,n,t,s,o="NHWC",i=[1,1],u){const l=(0,r.q)(e,"x","depthwiseConv2d","float32"),h=(0,r.q)(n,"filter","depthwiseConv2d","float32");let c=l,p=!1;3===l.rank&&(p=!0,c=(0,r.r)(l,[1,l.shape[0],l.shape[1],l.shape[2]])),(0,a.a)(4===c.rank,(()=>`Error in depthwiseConv2d: input must be rank 4, but got rank ${c.rank}.`)),(0,a.a)(4===h.rank,(()=>`Error in depthwiseConv2d: filter must be rank 4, but got rank ${h.rank}.`)),(0,a.a)(c.shape[3]===h.shape[2],(()=>`Error in depthwiseConv2d: number of input channels (${c.shape[3]}) must match the inChannels dimension in filter ${h.shape[2]}.`)),(0,r.Q)("depthwiseConv2d",s,u);const d={x:c,filter:h},f={strides:t,pad:s,dataFormat:o,dilations:i,dimRoundingMode:u},m=r.E.runKernel(r.ac,d,f);return p?(0,r.r)(m,[m.shape[1],m.shape[2],m.shape[3]]):m}}),Z=(0,r.o)({dilation2d_:function(e,n,t,s,o=[1,1],i="NHWC"){const u=(0,r.q)(e,"x","dilation2d"),l=(0,r.q)(n,"filter","dilation2d");(0,a.a)(3===u.rank||4===u.rank,(()=>`Error in dilation2d: input must be rank 3 or 4, but got rank ${u.rank}.`)),(0,a.a)(3===l.rank,(()=>`Error in dilation2d: filter must be rank 3, but got rank ${l.rank}.`)),(0,a.a)("NHWC"===i,(()=>`Error in dilation2d: Only NHWC is currently supported, but got dataFormat of ${i}`));let h=u,c=!1;3===u.rank&&(h=(0,r.r)(u,[1,u.shape[0],u.shape[1],u.shape[2]]),c=!0);const p={x:h,filter:l},d={strides:t,pad:s,dilations:o},f=r.E.runKernel(r.ad,p,d);return c?(0,r.r)(f,[f.shape[1],f.shape[2],f.shape[3]]):f}}),Q=(0,r.o)({equal_:function(e,n){let t=(0,r.q)(e,"a","equal","string_or_numeric"),a=(0,r.q)(n,"b","equal","string_or_numeric");[t,a]=(0,r.u)(t,a),(0,r.ae)(t.shape,a.shape);const s={a:t,b:a};return r.E.runKernel(r.af,s)}}),j=(0,r.o)({where_:function(e,n,t){const a=(0,r.q)(n,"a","where"),s=(0,r.q)(t,"b","where"),o=(0,r.q)(e,"condition","where","bool"),i=(0,r.ae)((0,r.ae)(o.shape,a.shape),s.shape),u={condition:C(o,i),t:C(a,i),e:C(s,i)};return r.E.runKernel(r.ag,u)}}),J=(0,r.o)({zerosLike_:function(e){const n={x:(0,r.q)(e,"x","zerosLike")};return r.E.runKernel(r.ah,n)}}),X=(0,r.o)({divNoNan_:function(e,n){let t=(0,r.q)(e,"a","div"),a=(0,r.q)(n,"b","div");[t,a]=(0,r.u)(t,a);const s=p(t,a),o=J(s),i=Q(a,o);return j(i,o,s)}}),ee=(0,r.o)({einsum_:function(e,...n){const t=n.map(((e,n)=>(0,r.q)(e,`tensors${n}`,"einsum"))),a={equation:e};return r.E.runKernel(r.ai,t,a)}}),ne=(0,r.o)({erf_:function(e){let n=(0,r.q)(e,"x","erf");(0,a.a)("int32"===n.dtype||"float32"===n.dtype,(()=>"Input dtype must be `int32` or `float32`.")),"int32"===n.dtype&&(n=(0,r.c)(n,"float32"));const t={x:n};return r.E.runKernel(r.aj,t)}}),te=(0,r.o)({exp_:function(e){const n={x:(0,r.q)(e,"x","exp")};return r.E.runKernel(r.ak,n)}}),re=(0,r.o)({expandDims_:function(e,n=0){const t=(0,r.q)(e,"x","expandDims","string_or_numeric");(0,a.a)(n<=t.rank,(()=>"Axis must be <= rank of the tensor"));const s={input:t},o={dim:n};return r.E.runKernel(r.al,s,o)}}),ae=(0,r.o)({expm1_:function(e){const n={x:(0,r.q)(e,"x","expm1")};return r.E.runKernel(r.am,n)}}),se=(0,r.o)({tile_:function(e,n){const t=(0,r.q)(e,"x","tile","string_or_numeric");(0,a.a)(t.rank===n.length,(()=>`Error in transpose: rank of input ${t.rank} must match length of reps ${n}.`));const s={x:t},o={reps:n};return r.E.runKernel(r.a1,s,o)}}),oe=(0,r.o)({eye_:function(e,n,t,a="float32"){null==n&&(n=e);const s=(0,r.n)([e,n],a),o=e<=n?e:n;for(let e=0;e<o;++e)s.set(1,e,e);const i=(0,r.r)(s.toTensor(),[e,n]);if(null==t)return i;if(1===t.length)return se(re(i,0),[t[0],1,1]);if(2===t.length)return se(re(re(i,0),0),[t[0],t[1],1,1]);if(3===t.length)return se(re(re(re(i,0),0),0),[t[0],t[1],t[2],1,1]);throw new Error(`eye() currently supports only 1D and 2D batchShapes, but received ${t.length}D.`)}});function ie(e,n,t){const a={shape:e,value:n,dtype:t};return r.E.runKernel(r.an,{},a)}const ue=(0,r.o)({floor_:function(e){const n={x:(0,r.q)(e,"x","floor","float32")};return r.E.runKernel(r.ao,n)}}),le=(0,r.o)({gather_:function(e,n,t=0,a=0){const s={x:(0,r.q)(e,"x","gather"),indices:(0,r.q)(n,"indices","gather","int32")},o={axis:t,batchDims:a};return r.E.runKernel(r.ap,s,o)}}),he=(0,r.o)({greater_:function(e,n){let t=(0,r.q)(e,"a","greater","string_or_numeric"),a=(0,r.q)(n,"b","greater","string_or_numeric");[t,a]=(0,r.u)(t,a),(0,r.ae)(t.shape,a.shape);const s={a:t,b:a};return r.E.runKernel(r.aq,s)}}),ce=(0,r.o)({greaterEqual_:function(e,n){let t=(0,r.q)(e,"a","greaterEqual","string_or_numeric"),a=(0,r.q)(n,"b","greaterEqual","string_or_numeric");[t,a]=(0,r.u)(t,a),(0,r.ae)(t.shape,a.shape);const s={a:t,b:a};return r.E.runKernel(r.ar,s)}}),pe=(0,r.o)({imag_:function(e){const n={input:(0,r.q)(e,"input","imag")};return r.E.runKernel(r.as,n)}}),de=(0,r.o)({isNaN_:function(e){const n={x:(0,r.q)(e,"x","isNaN")};return r.E.runKernel(r.at,n)}}),fe=(0,r.o)({less_:function(e,n){let t=(0,r.q)(e,"a","less","string_or_numeric"),a=(0,r.q)(n,"b","less","string_or_numeric");[t,a]=(0,r.u)(t,a),(0,r.ae)(t.shape,a.shape);const s={a:t,b:a};return r.E.runKernel(r.au,s)}}),me=(0,r.o)({lessEqual_:function(e,n){let t=(0,r.q)(e,"a","lessEqual","string_or_numeric"),a=(0,r.q)(n,"b","lessEqual","string_or_numeric");[t,a]=(0,r.u)(t,a),(0,r.ae)(t.shape,a.shape);const s={a:t,b:a};return r.E.runKernel(r.av,s)}});function be(e,n,t){if(t<=0)throw new Error("The number of values should be positive.");const a={start:e,stop:n,num:t};return r.E.runKernel(r.aw,{},a)}const ge=(0,r.o)({localResponseNormalization_:function(e,n=5,t=1,s=1,o=.5){const i=(0,r.q)(e,"x","localResponseNormalization");(0,a.a)(4===i.rank||3===i.rank,(()=>`Error in localResponseNormalization: x must be rank 3 or 4 but got\n               rank ${i.rank}.`)),(0,a.a)((0,a.c)(n),(()=>`Error in localResponseNormalization: depthRadius must be an integer but got depthRadius ${n}.`));let u=i,l=!1;3===i.rank&&(l=!0,u=(0,r.r)(i,[1,i.shape[0],i.shape[1],i.shape[2]]));const h={x:u},c={depthRadius:n,bias:t,alpha:s,beta:o},p=r.E.runKernel(r.ax,h,c);return l?(0,r.r)(p,[p.shape[1],p.shape[2],p.shape[3]]):p}}),Ee=(0,r.o)({log_:function(e){const n={x:(0,r.q)(e,"x","log","float32")};return r.E.runKernel(r.ay,n)}}),ke=(0,r.o)({log1p_:function(e){const n={x:(0,r.q)(e,"x","log1p")};return r.E.runKernel(r.az,n)}});function xe(e,n){(0,a.a)((0,a.d)(e),(()=>"The f passed in variableGrads(f) must be a function")),(0,a.a)(null==n||Array.isArray(n)&&n.every((e=>e instanceof r.aA)),(()=>"The varList passed in variableGrads(f, varList) must be an array of variables"));const t=null!=n;if(!t){n=[];for(const e in r.E.registeredVariables)n.push(r.E.registeredVariables[e])}const s=t?n.filter((e=>!e.trainable)):null,o=n.length;n=n.filter((e=>e.trainable)),(0,a.a)(n.length>0,(()=>`variableGrads() expects at least one of the input variables to be trainable, but none of the ${o} variables is trainable.`));const{value:i,grads:u}=r.E.gradients(e,n,null,!0);(0,a.a)(u.some((e=>null!=e)),(()=>"Cannot find a connection between any variable and the result of the loss function y=f(x). Please make sure the operations that use variables are inside the function f passed to minimize().")),(0,a.a)(0===i.rank,(()=>`The f passed in variableGrads(f) must return a scalar, but it returned a rank-${i.rank} tensor`));const l={};return n.forEach(((e,n)=>{null!=u[n]&&(l[e.name]=u[n])})),null!=s&&s.forEach((e=>l[e.name]=null)),{value:i,grads:l}}function qe(e){return r.E.customGrad(e)}const _e=(0,r.o)({neg_:function(e){const n={x:(0,r.q)(e,"x","neg")};return r.E.runKernel(r.aB,n)}}),we=(0,r.o)({softplus_:function(e){const n={x:(0,r.q)(e,"x","softplus")};return r.E.runKernel(r.aC,n)}}),ve=(0,r.o)({max_:function(e,n=null,t=!1){const a={x:(0,r.q)(e,"x","max")},s={reductionIndices:n,keepDims:t};return r.E.runKernel(r.aD,a,s)}}),$e=(0,r.o)({sub_:function(e,n){let t=(0,r.q)(e,"a","sub"),a=(0,r.q)(n,"b","sub");[t,a]=(0,r.u)(t,a);const s={a:t,b:a};return r.E.runKernel(r.aE,s)}}),ye=(0,r.o)({logSoftmax_:function(e,n=-1){const t=(0,r.q)(e,"logits","logSoftmax");if(-1===n&&(n=t.rank-1),n!==t.rank-1)throw Error(`Log Softmax along a non-last dimension is not yet supported. Logits was rank ${t.rank} and axis was ${n}`);const a=qe(((e,t)=>{const a=ve(e,n,!0),s=$e(e,a),o=$e((0,r.c)(s,"float32"),Ee((0,r.h)(te(s),n,!0)));return t([o]),{value:o,gradFunc:(e,t)=>{const[a]=t,s=te(a);return $e(e,(0,r.m)((0,r.h)(e,n,!0),s))}}}));return a(t)}}),Se=(0,r.o)({logSumExp_:function(e,n=null,t=!1){const s=(0,r.q)(e,"x","logSumExp"),o=(0,a.p)(n,s.shape),i=ve(s,o,!0),u=$e(s,i),l=te(u),c=(0,r.h)(l,o),p=Ee(c),d=h((0,r.r)(i,p.shape),p);if(t){const e=(0,r.aF)(d.shape,o);return(0,r.r)(d,e)}return d}}),Ne=(0,r.o)({logicalAnd_:function(e,n){const t=(0,r.q)(e,"a","logicalAnd","bool"),a=(0,r.q)(n,"b","logicalAnd","bool");(0,r.ae)(t.shape,a.shape);const s={a:t,b:a};return r.E.runKernel(r.aG,s)}}),Ke=(0,r.o)({logicalNot_:function(e){const n={x:(0,r.q)(e,"x","logicalNot","bool")};return r.E.runKernel(r.aH,n)}}),Te=(0,r.o)({logicalOr_:function(e,n){const t=(0,r.q)(e,"a","logicalOr","bool"),a=(0,r.q)(n,"b","logicalOr","bool");(0,r.ae)(t.shape,a.shape);const s={a:t,b:a};return r.E.runKernel(r.aI,s)}}),De=(0,r.o)({maxPool_:function(e,n,t,s,o){const i=(0,r.q)(e,"x","maxPool");let u=i,l=!1;3===i.rank&&(l=!0,u=(0,r.r)(i,[1,i.shape[0],i.shape[1],i.shape[2]])),(0,a.a)(4===u.rank,(()=>`Error in maxPool: input must be rank 4 but got rank ${u.rank}.`)),(0,a.a)((0,r.P)(t,1),(()=>`Error in maxPool: Either strides or dilations must be 1. Got strides ${t} and dilations '1'`)),(0,r.Q)("maxPool",s,o);const h={x:u},c={filterSize:n,strides:t,pad:s,dimRoundingMode:o},p=r.E.runKernel(r.aJ,h,c);return l?(0,r.r)(p,[p.shape[1],p.shape[2],p.shape[3]]):p}}),Me=(0,r.o)({maxPool3d_:function(e,n=[1,1,1],t,s,o,i="NDHWC"){const u=(0,r.q)(e,"x","maxPool3d");let l=u,h=!1;4===u.rank&&(h=!0,l=(0,r.r)(u,[1,u.shape[0],u.shape[1],u.shape[2],u.shape[3]])),(0,a.a)(5===l.rank,(()=>`Error in maxPool3d: x must be rank 5 but got rank ${l.rank}.`)),(0,a.a)("NDHWC"===i,(()=>`Error in maxPool3d: Only NDHWC is currently supported, but got dataFormat of ${i}`)),(0,r.Q)("maxPool3d",s,o);const c={x:l},p={filterSize:n,strides:t,pad:s,dimRoundingMode:o,dataFormat:i},d=r.E.runKernel(r.aK,c,p);return h?(0,r.r)(d,[d.shape[1],d.shape[2],d.shape[3],d.shape[4]]):d}}),ze=(0,r.o)({maxPoolWithArgmax_:function(e,n,t,a,s=!1){const o={x:(0,r.q)(e,"x","maxPoolWithArgmax")},i={filterSize:n,strides:t,pad:a,includeBatchInIndex:s},u=r.E.runKernel(r.aL,o,i);return{result:u[0],indexes:u[1]}}}),Ie=(0,r.o)({maximum_:function(e,n){let t=(0,r.q)(e,"a","maximum"),a=(0,r.q)(n,"b","maximum");[t,a]=(0,r.u)(t,a),"bool"===t.dtype&&(t=(0,r.c)(t,"int32"),a=(0,r.c)(a,"int32")),(0,r.ae)(t.shape,a.shape);const s={a:t,b:a};return r.E.runKernel(r.aM,s)}}),Ce=(0,r.o)({mean_:function(e,n=null,t=!1){const a={x:(0,r.q)(e,"x","mean")},s={axis:n,keepDims:t};return r.E.runKernel(r.aN,a,s)}});function Ae(e,n="float32"){if("complex64"===n){const n=Ae(e,"float32"),t=(0,o.z)(e,"float32");return(0,r.g)(n,t)}const t=(0,a.m)((0,a.s)(e),n);return r.E.makeTensor(t,e,n)}const We=(0,r.o)({min_:function(e,n=null,t=!1){const a={x:(0,r.q)(e,"x","min")},s={axis:n,keepDims:t};return r.E.runKernel(r.aO,a,s)}}),Re=(0,r.o)({minimum_:function(e,n){let t=(0,r.q)(e,"a","minimum"),a=(0,r.q)(n,"b","minimum");[t,a]=(0,r.u)(t,a),"bool"===t.dtype&&(t=(0,r.c)(t,"int32"),a=(0,r.c)(a,"int32")),(0,r.ae)(t.shape,a.shape);const s={a:t,b:a};return r.E.runKernel(r.aP,s)}}),Pe=(0,r.o)({mirrorPad_:function(e,n,t){(0,a.a)("reflect"===t||"symmetric"===t,(()=>`Invalid mode. Mode must be either reflect or symmetric. Got ${t}.`));const s=(0,r.q)(e,"x","mirrorPad");if(0===s.rank)throw new Error("mirrorPad(scalar) is not defined. Pass non-scalar to mirrorPad");(0,a.a)(n.length===s.rank,(()=>`Padding doesn't match input. Must be ${s.rank}. Got ${n.length}.`));const o="reflect"===t?1:0;for(let e=0;e<s.rank;e++)(0,a.a)(2===n[e].length,(()=>"Invalid number of paddings. Must be length of 2 each.")),(0,a.a)(n[e][0]>=0&&n[e][0]<=s.shape[e]-o&&n[e][1]>=0&&n[e][1]<=s.shape[e]-o,(()=>`Padding in dimension ${e} cannot be greater than or equal to ${s.shape[e]-o} or less than 0 for input of shape ${s.shape}`));const i={paddings:n,mode:t},u={x:s};return r.E.runKernel(r.aQ,u,i)}}),Fe=(0,r.o)({mod_:function(e,n){let t=(0,r.q)(e,"a","mod"),a=(0,r.q)(n,"b","mod");[t,a]=(0,r.u)(t,a);const s={a:t,b:a};return r.E.runKernel(r.aR,s)}}),Oe=(0,r.o)({square_:function(e){const n=(0,r.q)(e,"x","square");return r.E.runKernel("Square",{x:n},{})}}),He=(0,r.o)({multinomial_:function(e,n,t,a=!1){const s=(0,r.q)(e,"logits","multinomial"),o=s.size,i=s.rank;if(o<2)throw new Error(`Error in multinomial: you need at least 2 outcomes, but got ${o}.`);if(i>2)throw new Error(`Rank of probabilities must be 1 or 2, but is ${i}`);t=t||Math.random();const u={logits:1===i?(0,r.r)(s,[1,-1]):s},l={numSamples:n,seed:t,normalized:a},h=r.E.runKernel(r.aS,u,l);return 1===i?(0,r.r)(h,[h.size]):h}}),Ve=(0,r.o)({notEqual_:function(e,n){let t=(0,r.q)(e,"a","notEqual","string_or_numeric"),a=(0,r.q)(n,"b","notEqual","string_or_numeric");[t,a]=(0,r.u)(t,a),(0,r.ae)(t.shape,a.shape);const s={a:t,b:a};return r.E.runKernel(r.aT,s)}}),Be=(0,r.o)({onesLike_:function(e){const n={x:(0,r.q)(e,"x","onesLike")};return r.E.runKernel(r.aU,n)}}),Ge=(0,r.o)({pad_:function(e,n,t=0){const a=(0,r.q)(e,"x","pad");if(0===a.rank)throw new Error("pad(scalar) is not defined. Pass non-scalar to pad");const s={paddings:n,constantValue:t},o={x:a};return r.E.runKernel(r.aV,o,s)}}),Le=(0,r.o)({spaceToBatchND_:function(e,n,t){const s=(0,r.q)(e,"x","spaceToBatchND");(0,a.a)(s.rank>=1+n.length,(()=>`input rank ${s.rank} should be > than [blockShape] ${n.length}`)),(0,a.a)(t.length===n.length,(()=>`paddings.shape[0] ${t.length} must be equal to [blockShape] ${n.length}`)),(0,a.a)(s.shape.reduce(((e,r,a)=>a>0&&a<=n.length?e&&(r+t[a-1][0]+t[a-1][1])%n[a-1]==0:e),!0),(()=>`input spatial dimensions ${s.shape.slice(1)} with paddings ${t.toString()} must be divisible by blockShapes ${n.toString()}`));const o={x:s},i={blockShape:n,paddings:t};return r.E.runKernel(r.aW,o,i)}}),Ue=(0,r.o)({pow_:function(e,n){let t=(0,r.q)(e,"base","pow"),a=(0,r.q)(n,"exp","pow");[t,a]=(0,r.u)(t,a);const s={a:t,b:a};return r.E.runKernel(r.aX,s)}}),Ye=(0,r.o)({prod_:function(e,n=null,t=!1){let a=(0,r.q)(e,"x","prod");"bool"===a.dtype&&(a=(0,r.c)(a,"int32"));const s={x:a},o={axis:n,keepDims:t};return r.E.runKernel(r.aY,s,o)}});class Ze{constructor(e,n,t,r,a){this.mean=e,this.stdDev=n,this.dtype=t,this.nextVal=NaN,this.truncated=r,this.truncated&&(this.upper=this.mean+2*this.stdDev,this.lower=this.mean-2*this.stdDev);const o=a||Math.random();this.random=s.s.alea(o.toString())}nextValue(){if(!isNaN(this.nextVal)){const e=this.nextVal;return this.nextVal=NaN,e}let e,n,t=!1;for(;!t;){let r,a,s;do{r=2*this.random()-1,a=2*this.random()-1,s=r*r+a*a}while(s>=1||0===s);const o=Math.sqrt(-2*Math.log(s)/s);e=this.mean+this.stdDev*r*o,n=this.mean+this.stdDev*a*o,this.truncated&&!this.isValidTruncated(e)||(t=!0)}return this.truncated&&!this.isValidTruncated(n)||(this.nextVal=this.convertValue(n)),this.convertValue(e)}convertValue(e){return null==this.dtype||"float32"===this.dtype?e:Math.round(e)}isValidTruncated(e){return e<=this.upper&&e>=this.lower}}class Qe{constructor(e,n,t,r){this.alpha=e,this.beta=1/n,this.dtype=t;const a=r||Math.random();this.randu=s.s.alea(a.toString()),this.randn=new Ze(0,1,t,!1,this.randu()),this.d=e<1?e+2/3:e-1/3,this.c=1/Math.sqrt(9*this.d)}nextValue(){let e,n,t,r,a,s;for(;;){do{r=this.randn.nextValue(),s=1+this.c*r}while(s<=0);if(s*=s*s,e=r*r,n=1-.331*e*e,t=.5*e+this.d*(1-s+Math.log(s)),a=this.randu(),a<n||Math.log(a)<t)break}return s=1/this.beta*this.d*s,this.alpha<1&&(s*=Math.pow(this.randu(),1/this.alpha)),this.convertValue(s)}convertValue(e){return"float32"===this.dtype?e:Math.round(e)}}class je{constructor(e=0,n=1,t,r){if(this.canReturnFloat=()=>null==this.dtype||"float32"===this.dtype,this.min=e,this.range=n-e,this.dtype=t,null==r&&(r=Math.random()),"number"==typeof r&&(r=r.toString()),!this.canReturnFloat()&&this.range<=1)throw new Error(`The difference between ${e} - ${n} <= 1 and dtype is not float`);this.random=s.s.alea(r)}convertValue(e){return this.canReturnFloat()?e:Math.round(e)}nextValue(){return this.convertValue(this.min+this.range*this.random())}}const Je=(0,r.o)({randomUniform_:function(e,n=0,t=1,a="float32",s){const o=(0,r.n)(e,a),i=new je(n,t,null,s);for(let e=0;e<o.values.length;e++)o.values[e]=i.nextValue();return o.toTensor()}});function Xe(e,n,t=1,a="float32"){if(0===t)throw new Error("Cannot have a step of zero");const s={start:e,stop:n,step:t,dtype:a};return r.E.runKernel(r.aZ,{},s)}const en=(0,r.o)({real_:function(e){const n={input:(0,r.q)(e,"input","real")};return r.E.runKernel(r.a_,n)}}),nn=(0,r.o)({reciprocal_:function(e){const n={x:(0,r.q)(e,"x","reciprocal")};return r.E.runKernel(r.a$,n)}}),tn=(0,r.o)({reverse_:function(e,n){const t={x:(0,r.q)(e,"x","reverse")},a={dims:n};return r.E.runKernel(r.b0,t,a)}}),rn=(0,r.o)({round_:function(e){const n={x:(0,r.q)(e,"x","round")};return r.E.runKernel(r.b1,n)}}),an=(0,r.o)({rsqrt_:function(e){const n={x:(0,r.q)(e,"x","rsqrt","float32")};return r.E.runKernel(r.b2,n)}}),sn=(0,r.o)({selu_:function(e){const n={x:(0,r.q)(e,"x","selu")};return r.E.runKernel(r.b3,n)}}),on=async function(e,n){const t=(0,r.q)(e,"x","setdiff1d"),s=(0,r.q)(n,"y","setdiff1d");(0,a.a)(t.dtype===s.dtype,(()=>`x and y should have the same dtype, but got x (${t.dtype}) and y (${s.dtype}).`)),(0,a.a)(1===t.rank,(()=>`x should be 1D tensor, but got x (${t.shape}).`)),(0,a.a)(1===s.rank,(()=>`y should be 1D tensor, but got y (${s.shape}).`));const o=await t.data(),i=await s.data(),u=new Set(i);let l=0;for(let e=0;e<o.length;e++)u.has(o[e])||l++;const h=new r.b4([l],t.dtype),c=new r.b4([l],"int32");for(let e=0,n=0;e<o.length;e++)u.has(o[e])||(h.values[n]=o[e],c.values[n]=e,n++);return[h.toTensor(),c.toTensor()]},un=(0,r.o)({sign_:function(e){const n={x:(0,r.q)(e,"x","sign")};return r.E.runKernel(r.b5,n)}}),ln=(0,r.o)({sin_:function(e){const n={x:(0,r.q)(e,"x","sin","float32")};return r.E.runKernel(r.b6,n)}}),hn=(0,r.o)({sinh_:function(e){const n={x:(0,r.q)(e,"x","sinh")};return r.E.runKernel(r.b7,n)}}),cn=(0,r.o)({softmax_:function(e,n=-1){const t=(0,r.q)(e,"logits","softmax","float32");if(-1===n&&(n=t.rank-1),n!==t.rank-1)throw Error(`Softmax along a non-last dimension is not yet supported. Logits was rank ${t.rank} and dim was ${n}`);const a={logits:t},s={dim:n};return r.E.runKernel(r.b8,a,s)}}),pn=(0,r.o)({fft_:function(e){(0,a.a)("complex64"===e.dtype,(()=>`The dtype for tf.spectral.fft() must be complex64 but got ${e.dtype}.`));const n={input:e};return r.E.runKernel(r.b9,n)}}),dn=(0,r.o)({ifft_:function(e){(0,a.a)("complex64"===e.dtype,(()=>`The dtype for tf.spectral.ifft() must be complex64 but got ${e.dtype}.`));const n={input:e};return r.E.runKernel(r.ba,n)}}),fn=(0,r.o)({irfft_:function(e){const n=e.shape[e.shape.length-1],t=e.size/n;let a;if(n<=2){const s=(0,r.r)(e,[t,n]);a=dn(s)}else{const s=[t,2*(n-1)],i=(0,r.r)(en(e),[t,n]),u=(0,r.r)(pe(e),[t,n]),l=tn(K(i,[0,1],[t,n-2]),1),h=(0,r.m)(tn(K(u,[0,1],[t,n-2]),1),(0,o.s)(-1)),c=N([i,l],1),p=N([u,h],1),d=(0,r.r)((0,r.g)(c,p),[s[0],s[1]]);a=dn(d)}if(a=en(a),3===e.rank&&0!==e.shape[0]){const n=a,t=e.shape[0];a=(0,r.r)(a,[t,a.shape[0]/t,a.shape[1]]),n.dispose()}return a}}),mn=(0,r.o)({split_:function(e,n,t=0){const a={x:(0,r.q)(e,"x","split")},s={numOrSizeSplits:n,axis:t};return r.E.runKernel(r.bb,a,s)}}),bn=(0,r.o)({rfft_:function(e,n){(0,a.a)("float32"===e.dtype,(()=>`The dtype for rfft() must be real value but got ${e.dtype}`));let t=e.shape[e.shape.length-1];const s=e.size/t;let i;if(null!=n&&n<t){const r=e.shape.map((e=>0)),a=e.shape.map((e=>e));a[e.shape.length-1]=n,i=K(e,r,a),t=n}else if(null!=n&&n>t){const r=e.shape.map((e=>e));r[e.shape.length-1]=n-t,i=N([e,(0,o.z)(r)],e.shape.length-1),t=n}else i=e;const u=J(i),l=(0,r.r)((0,r.g)(i,u),[s,t]),h=pn(l),c=Math.floor(t/2)+1,p=en(h),d=pe(h),f=mn(p,[c,t-c],p.shape.length-1),m=mn(d,[c,t-c],d.shape.length-1),b=i.shape.slice();return b[i.shape.length-1]=c,(0,r.r)((0,r.g)(f[0],m[0]),b)}}),gn=(0,r.o)({sqrt_:function(e){const n={x:(0,r.q)(e,"x","sqrt","float32")};return r.E.runKernel(r.bc,n)}}),En=(0,r.o)({squaredDifference_:function(e,n){let t=(0,r.q)(e,"a","squaredDifference"),a=(0,r.q)(n,"b","squaredDifference");[t,a]=(0,r.u)(t,a),(0,r.ae)(t.shape,a.shape);const s={a:t,b:a};return r.E.runKernel(r.bd,s,{})}}),kn=(0,r.o)({squeeze_:function(e,n){const t=(0,r.q)(e,"x","squeeze");return(0,r.r)(t,(0,a.f)(t.shape,n).newShape)}}),xn=(0,r.o)({stack_:function(e,n=0){const t=(0,r.V)(e,"tensors","stack","string_or_numeric");(0,a.a)(t.length>=1,(()=>"Pass at least one tensor to tf.stack")),t.length>0&&(0,a.a)(n<=t[0].rank,(()=>"Axis must be <= rank of the tensor"));const s=t,o={axis:n};return r.E.runKernel(r.be,s,o)}}),qn=(0,r.o)({stridedSlice_:function(e,n,t,a,s=0,o=0,i=0,u=0,l=0){const h={x:(0,r.q)(e,"x","stridedSlice","string_or_numeric")},c={begin:n,end:t,strides:a,beginMask:s,endMask:o,ellipsisMask:i,newAxisMask:u,shrinkAxisMask:l};return r.E.runKernel(r.bf,h,c)}}),_n=(0,r.o)({tan_:function(e){const n={x:(0,r.q)(e,"x","tan","float32")};return r.E.runKernel(r.bg,n)}});function wn(e,n){(0,a.g)(e);const t=(0,r.bh)(e,n);if(1!==t.length)throw new Error("tensor1d() requires values to be a flat/TypedArray");return(0,r.bi)(e,null,t,n)}function vn(e,n,t){if((0,a.g)(e),null!=n&&2!==n.length)throw new Error("tensor2d() requires shape to have two numbers");const s=(0,r.bh)(e,t);if(2!==s.length&&1!==s.length)throw new Error("tensor2d() requires values to be number[][] or flat/TypedArray");if(1===s.length&&null==n)throw new Error("tensor2d() requires shape to be provided when `values` are a flat/TypedArray");return(0,r.bi)(e,n,s,t)}const $n=(0,r.o)({topk_:function(e,n=1,t=!0){const a=(0,r.q)(e,"x","topk");if(0===a.rank)throw new Error("topk() expects the input to be of rank 1 or higher");const s=a.shape[a.shape.length-1];if(n<0)throw new Error(`'k' passed to topk() must be >= 0 but got ${n}`);if(n>s)throw new Error(`'k' passed to topk() must be <= the last dimension (${s}) but got ${n}`);const o={x:a},i={k:n,sorted:t},[u,l]=r.E.runKernel(r.bj,o,i);return{values:u,indices:l}}}),yn=(0,r.o)({truncatedNormal_:function(e,n=0,t=1,a,s){if(null!=a&&"bool"===a)throw new Error("Unsupported data type $ { dtype }");const o=new Ze(n,t,a,!0,s),i=(0,r.n)(e,a);for(let e=0;e<i.values.length;e++)i.values[e]=o.nextValue();return i.toTensor()}}),Sn=(0,r.o)({unique_:function(e,n=0){const t=(0,r.q)(e,"x","unique","string_or_numeric");(0,a.a)(t.rank>0,(()=>"The input tensor must be at least 1D"));const s={x:t},o={axis:n},[i,u]=r.E.runKernel(r.bk,s,o);return{values:i,indices:u}}}),Nn=(0,r.o)({unstack_:function(e,n=0){const t=(0,r.q)(e,"x","unstack","string_or_numeric");(0,a.a)(n>=-t.shape.length&&n<t.shape.length,(()=>`Axis = ${n} is not in [-${t.shape.length}, ${t.shape.length})`));const s={value:t},o={axis:n};return r.E.runKernel(r.bl,s,o)}}),Kn=async function(e){const n=(0,r.q)(e,"condition","whereAsync","bool"),t=await n.data(),a=(0,o.w)(n.shape,t);return e!==n&&n.dispose(),a};function Tn(e,n,t=null){if(0===e.rank)return d(e);if(1!==e.rank&&null===t)return Tn((0,r.r)(e,[-1]),n,t);if(1===e.rank||"number"==typeof t||Array.isArray(t)&&1===t.length){if(1===n)return(0,r.h)(d(e),t);if(n===1/0)return ve(d(e),t);if(n===-1/0)return We(d(e),t);if("euclidean"===n||2===n)return gn((0,r.h)(Ue(d(e),(0,o.s)(2,"int32")),t));throw new Error(`Error in norm: invalid ord value: ${n}`)}if(Array.isArray(t)&&2===t.length){if(1===n)return ve((0,r.h)(d(e),t[0]),t[1]-1);if(n===1/0)return ve((0,r.h)(d(e),t[1]),t[0]);if(n===-1/0)return We((0,r.h)(d(e),t[1]),t[0]);if("fro"===n||"euclidean"===n)return gn((0,r.h)(Oe(e),t));throw new Error(`Error in norm: invalid ord value: ${n}`)}throw new Error(`Error in norm: invalid axis: ${t}`)}const Dn=(0,r.o)({norm_:function(e,n="euclidean",t=null,s=!1){const o=Tn(e=(0,r.q)(e,"x","norm"),n,t);let i=o.shape;if(s){const n=(0,a.p)(t,e.shape);i=(0,r.aF)(o.shape,n)}return(0,r.r)(o,i)}}),Mn=(0,r.o)({scatterND_:function(e,n,t){const a=(0,r.q)(e,"indices","scatterND","int32"),s=(0,r.q)(n,"updates","scatterND");(0,r.bm)(s,a,t);const o={indices:a,updates:s},i={shape:t};return r.E.runKernel(r.bn,o,i)}}),zn=(0,r.o)({sparseToDense_:function(e,n,t,a=0){const s=(0,r.q)(e,"sparseIndices","sparseToDense","int32"),o=(0,r.q)(n,"sparseValues","sparseToDense"),i=(0,r.q)(a,"defaultValue","sparseToDense",o.dtype);!function(e,n,t,r){if("int32"!==e.dtype)throw new Error(`tf.sparseToDense() expects the indices to be int32 type, but the dtype was ${e.dtype}.`);if(e.rank>2)throw new Error(`sparseIndices should be a scalar, vector, or matrix, but got shape ${e.shape}.`);const a=e.rank>0?e.shape[0]:1,s=e.rank>1?e.shape[1]:1;if(t.length!==s)throw new Error(`outputShape has incorrect number of elements:, ${t.length}, should be: ${s}.`);const o=n.size;if(0!==n.rank&&(1!==n.rank||o!==a))throw new Error(`sparseValues has incorrect shape ${n.shape}, should be [] or [${a}]`);if(n.dtype!==r.dtype)throw new Error("sparseValues.dtype must match defaultValues.dtype")}(s,o,t,i);const u={sparseIndices:s,sparseValues:o,defaultValue:i},l={outputShape:t};return r.E.runKernel(r.bo,u,l)}}),In=(0,r.o)({gatherND_:function(e,n){const t=(0,r.q)(n,"indices","gatherND","int32"),a={params:(0,r.q)(e,"x","gatherND","string_or_numeric"),indices:t};return r.E.runKernel(r.bp,a)}});function Cn(e,n,t){const r=1-e%2,a=new Float32Array(e);for(let s=0;s<e;++s){const o=2*Math.PI*s/(e+r-1);a[s]=n-t*Math.cos(o)}return wn(a,"float32")}const An=(0,r.o)({conv2DBackpropFilter_:function(e,n,t,s,o,i="NHWC",u){let l=e;3===e.rank&&(l=(0,r.r)(e,[1,e.shape[0],e.shape[1],e.shape[2]]));let h=n;3===h.rank&&(h=(0,r.r)(n,[1,n.shape[0],n.shape[1],n.shape[2]])),(0,a.a)(4===l.rank,(()=>`Error in conv2dDerFilter: input must be rank 4, but got shape ${l.shape}.`)),(0,a.a)(4===h.rank,(()=>`Error in conv2dDerFilter: dy must be rank 4, but got shape ${h.shape}.`)),(0,a.a)(4===t.length,(()=>`Error in conv2dDerFilter: filterShape must be length 4, but got ${t}.`));const c="NHWC"===i?l.shape[3]:l.shape[1],p="NHWC"===i?h.shape[3]:h.shape[1];(0,a.a)(c===t[2],(()=>`Error in conv2dDerFilter: depth of input ${c}) must match input depth in filter (${t[2]}.`)),(0,a.a)(p===t[3],(()=>`Error in conv2dDerFilter: depth of dy (${p}) must match output depth for filter (${t[3]}).`)),(0,r.Q)("conv2dDerFilter",o,u);const d={x:l,dy:h},f={strides:s,pad:o,dataFormat:i,dimRoundingMode:u,filterShape:t};return r.E.runKernel(r.bq,d,f)}}),Wn=(0,r.o)({fusedConv2d_:function({x:e,filter:n,strides:t,pad:s,dataFormat:o="NHWC",dilations:i=[1,1],dimRoundingMode:u,bias:l,activation:c="linear",preluActivationWeights:p,leakyreluAlpha:d}){if(c=c||"linear",!1===(0,r.br)(r.E.state.gradientDepth,c)){let a=R(e,n,t,s,o,i,u);return null!=l&&(a=h(a,l)),(0,r.bs)(a,c,p,d)}const f=(0,r.q)(e,"x","conv2d","float32"),m=(0,r.q)(n,"filter","conv2d","float32");let b=f,g=!1;3===f.rank&&(g=!0,b=(0,r.r)(f,[1,f.shape[0],f.shape[1],f.shape[2]])),(0,a.a)(4===b.rank,(()=>`Error in fused conv2d: input must be rank 4, but got rank ${b.rank}.`)),(0,a.a)(4===m.rank,(()=>`Error in fused conv2d: filter must be rank 4, but got rank ${m.rank}.`)),(0,r.Q)("fused conv2d",s,u),(0,a.a)(b.shape[3]===m.shape[2],(()=>`Error in conv2d: depth of input (${b.shape[3]}) must match input depth for filter ${m.shape[2]}.`)),(0,a.a)((0,r.P)(t,i),(()=>`Error in conv2D: Either strides or dilations must be 1. Got strides ${t} and dilations '${i}'`)),(0,a.a)("NHWC"===o,(()=>`Error in conv2d: got dataFormat of ${o} but only NHWC is currently supported.`));const E=(0,r.bt)(b.shape,m.shape,t,i,s,u);let k,x;null!=l&&(k=(0,r.q)(l,"bias","fused conv2d"),[k]=(0,r.u)(k,f),(0,r.ae)(E.outShape,k.shape)),null!=p&&(x=(0,r.q)(p,"prelu weights","fused conv2d"));const q=(e,n)=>{const[o,u,l,h]=n,p=(0,r.bv)(e,l,c);(0,a.a)((0,r.bw)(i),(()=>`Error in gradient of fused conv2D: dilation rates greater than 1 are not yet supported in gradients. Got dilations '${i}'`));const d=[F(u.shape,p,o,t,s),An(u,p,o.shape,t,s)];if(null!=h){const e=(0,r.bx)(h,p);d.push(e)}return d},_={x:b,filter:m,bias:k,preluActivationWeights:x},w={strides:t,pad:s,dataFormat:o,dilations:i,dimRoundingMode:u,activation:c,leakyreluAlpha:d};if(null==l){const e=qe(((e,n,t)=>{let a=r.E.runKernel(r.bu,_,w);return t([n,e,a]),g&&(a=(0,r.r)(a,[a.shape[1],a.shape[2],a.shape[3]])),{value:a,gradFunc:q}}));return e(b,m)}{const e=qe(((e,n,t,a)=>{let s=r.E.runKernel(r.bu,_,w);return a([n,e,s,t]),g&&(s=(0,r.r)(s,[s.shape[1],s.shape[2],s.shape[3]])),{value:s,gradFunc:q}}));return e(b,m,k)}}}),Rn=(0,r.o)({depthwiseConv2dNativeBackpropFilter_:function(e,n,t,a,s,o=[1,1],i){let u=e;3===e.rank&&(u=(0,r.r)(e,[1,e.shape[0],e.shape[1],e.shape[2]]));let l=n;3===l.rank&&(l=(0,r.r)(n,[1,n.shape[0],n.shape[1],n.shape[2]]));const h={x:u,dy:l},c={strides:a,pad:s,dimRoundingMode:i,dilations:o,filterShape:t};return r.E.runKernel(r.by,h,c)}}),Pn=(0,r.o)({depthwiseConv2dNativeBackpropInput_:function(e,n,t,a,s,o=[1,1],i){let u=n,l=!1;3===n.rank&&(l=!0,u=(0,r.r)(n,[1,n.shape[0],n.shape[1],n.shape[2]]));const h={dy:u,filter:t},c={strides:a,pad:s,dimRoundingMode:i,dilations:o,inputShape:e},p=r.E.runKernel(r.bz,h,c);return l?(0,r.r)(p,[p.shape[1],p.shape[2],p.shape[3]]):p}}),Fn=(0,r.o)({fusedDepthwiseConv2d_:function({x:e,filter:n,strides:t,pad:s,dataFormat:o="NHWC",dilations:i=[1,1],dimRoundingMode:u,bias:l,activation:c="linear",preluActivationWeights:p,leakyreluAlpha:d}){if(!1===(0,r.br)(r.E.state.gradientDepth,c)){let a=Y(e,n,t,s,o,i,u);return null!=l&&(a=h(a,l)),(0,r.bs)(a,c,p,d)}const f=(0,r.q)(e,"x","depthwiseConv2d","float32"),m=(0,r.q)(n,"filter","depthwiseConv2d","float32");let b=f,g=!1;3===f.rank&&(g=!0,b=(0,r.r)(f,[1,f.shape[0],f.shape[1],f.shape[2]])),(0,a.a)(4===b.rank,(()=>`Error in fused depthwiseConv2d: input must be rank 4, but got rank ${b.rank}.`)),(0,a.a)(4===m.rank,(()=>`Error in fused depthwiseConv2d: filter must be rank 4, but got rank ${m.rank}.`)),(0,a.a)(b.shape[3]===m.shape[2],(()=>`Error in fused depthwiseConv2d: number of input channels (${b.shape[3]}) must match the inChannels dimension in filter ${m.shape[2]}.`)),null==i&&(i=[1,1]),(0,a.a)((0,r.P)(t,i),(()=>`Error in fused depthwiseConv2d: Either strides or dilations must be 1. Got strides ${t} and dilations '${i}'`)),(0,r.Q)("fused depthwiseConv2d",s,u);const E=(0,r.bt)(b.shape,m.shape,t,i,s,u,!0);let k,x;null!=l&&(k=(0,r.q)(l,"bias","fused conv2d"),[k]=(0,r.u)(k,f),(0,r.ae)(E.outShape,k.shape)),null!=p&&(x=(0,r.q)(p,"prelu weights","fused depthwiseConv2d"));const q=(e,n)=>{(0,a.a)((0,r.bw)(i),(()=>`Error in gradient of fused depthwiseConv2d: dilation rates greater than 1 are not yet supported. Got dilations '${i}'`));const[o,l,h,p]=n,d=(0,r.bv)(e,h,c),f=Pn(l.shape,d,o,t,s,i,u),m=Rn(l,d,o.shape,t,s,i,u);return null!=p?[f,m,(0,r.bx)(k,d)]:[f,m]},_={x:b,filter:m,bias:k,preluActivationWeights:x},w={strides:t,pad:s,dataFormat:o,dilations:i,dimRoundingMode:u,activation:c,leakyreluAlpha:d};if(null==l){const e=qe(((e,n,t)=>{let a=r.E.runKernel(r.bA,_,w);return t([n,e,a]),g&&(a=(0,r.r)(a,[a.shape[1],a.shape[2],a.shape[3]])),{value:a,gradFunc:q}}));return e(b,m)}{const e=qe(((e,n,t,a)=>{let s=r.E.runKernel(r.bA,_,w);return a([n,e,s,t]),g&&(s=(0,r.r)(s,[s.shape[1],s.shape[2],s.shape[3]])),{value:s,gradFunc:q}}));return e(b,m,k)}}}),On=(0,r.o)({fusedMatMul_:function({a:e,b:n,transposeA:t=!1,transposeB:s=!1,bias:o,activation:u="linear",preluActivationWeights:l,leakyreluAlpha:c}){if(!1===(0,r.br)(r.E.state.gradientDepth,u)){let a=i(e,n,t,s);return null!=o&&(a=h(a,o)),(0,r.bs)(a,u,l,c)}let p=(0,r.q)(e,"a","fused matMul"),d=(0,r.q)(n,"b","fused matMul");[p,d]=(0,r.u)(p,d);const f=t?p.shape[p.rank-2]:p.shape[p.rank-1],m=s?d.shape[d.rank-1]:d.shape[d.rank-2],b=t?p.shape[p.rank-1]:p.shape[p.rank-2],g=s?d.shape[d.rank-2]:d.shape[d.rank-1],E=p.shape.slice(0,-2),k=d.shape.slice(0,-2),x=(0,a.s)(E),q=(0,a.s)(k);(0,a.a)(f===m,(()=>`Error in fused matMul: inner shapes (${f}) and (${m}) of Tensors with shapes ${p.shape} and ${d.shape} and transposeA=${t} and transposeB=${s} must match.`));const _=(0,r.ae)(p.shape.slice(0,-2),d.shape.slice(0,-2)).concat([b,g]),w=t?(0,r.r)(p,[x,f,b]):(0,r.r)(p,[x,b,f]),v=s?(0,r.r)(d,[q,g,m]):(0,r.r)(d,[q,m,g]);let $,y;null!=o&&($=(0,r.q)(o,"bias","fused matMul"),[$]=(0,r.u)($,p),(0,r.ae)(_,$.shape)),null!=l&&(y=(0,r.q)(l,"prelu weights","fused matMul"));const S=(e,n)=>{const[a,l,h,c]=n,p=(0,r.bv)((0,r.r)(e,h.shape),h,u);let d,f;return t||s?!t&&s?(d=i(p,l,!1,!1),f=i(p,a,!0,!1)):t&&!s?(d=i(l,p,!1,!0),f=i(a,p,!1,!1)):(d=i(l,p,!0,!0),f=i(p,a,!0,!0)):(d=i(p,l,!1,!0),f=i(a,p,!0,!1)),null!=o?[d,f,(0,r.bx)(c,p)]:[d,f]},N={a:w,b:v,bias:$,preluActivationWeights:y},K={transposeA:t,transposeB:s,activation:u,leakyreluAlpha:c};if(null==o){const e=qe(((e,n,t)=>{const a=r.E.runKernel(r.bB,N,K);return t([e,n,a]),{value:(0,r.r)(a,_),gradFunc:S}}));return e(w,v)}{const e=qe(((e,n,t,a)=>{const s=r.E.runKernel(r.bB,N,K);return a([e,n,s,t]),{value:(0,r.r)(s,_),gradFunc:S}}));return e(w,v,$)}}});(0,r.o)({hammingWindow_:function(e){return Cn(e,.54,.46)}});const Hn=(0,r.o)({hannWindow_:function(e){return Cn(e,.5,.5)}}),Vn=(0,r.o)({frame_:function(e,n,t,a=!1,s=0){let o=0;const i=[];for(;o+n<=e.size;)i.push(K(e,o,n)),o+=t;if(a)for(;o<e.size;){const r=o+n-e.size,a=N([K(e,o,n-r),ie([r],s)]);i.push(a),o+=t}return 0===i.length?vn([],[0,n]):(0,r.r)(N(i),[i.length,n])}});(0,r.o)({stft_:function(e,n,t,a,s=Hn){var o;null==a&&(o=n,a=Math.floor(Math.pow(2,Math.ceil(Math.log(o)/Math.log(2)))));const i=Vn(e,n,t),u=(0,r.m)(i,s(n));return bn(u,a)}});const Bn=(0,r.o)({cropAndResize_:function(e,n,t,s,o="bilinear",i=0){const u=(0,r.q)(e,"image","cropAndResize"),l=(0,r.q)(n,"boxes","cropAndResize","float32"),h=(0,r.q)(t,"boxInd","cropAndResize","int32"),c=l.shape[0];(0,a.a)(4===u.rank,(()=>`Error in cropAndResize: image must be rank 4,but got rank ${u.rank}.`)),(0,a.a)(2===l.rank&&4===l.shape[1],(()=>`Error in cropAndResize: boxes must be have size [${c},4] but had shape ${l.shape}.`)),(0,a.a)(1===h.rank&&h.shape[0]===c,(()=>`Error in cropAndResize: boxInd must be have size [${c}] but had shape ${l.shape}.`)),(0,a.a)(2===s.length,(()=>`Error in cropAndResize: cropSize must be of length 2, but got length ${s.length}.`)),(0,a.a)(s[0]>=1&&s[1]>=1,(()=>`cropSize must be atleast [1,1], but was ${s}`)),(0,a.a)("bilinear"===o||"nearest"===o,(()=>`method must be bilinear or nearest, but was ${o}`));const p={image:u,boxes:l,boxInd:h},d={method:o,extrapolationValue:i,cropSize:s};return r.E.runKernel(r.bC,p,d)}}),Gn=(0,r.o)({flipLeftRight_:function(e){const n=(0,r.q)(e,"image","flipLeftRight","float32");(0,a.a)(4===n.rank,(()=>`Error in flipLeftRight: image must be rank 4,but got rank ${n.rank}.`));const t={image:n};return r.E.runKernel(r.bD,t,{})}}),Ln=(0,r.o)({grayscaleToRGB_:function(e){const n=(0,r.q)(e,"image","grayscaleToRGB"),t=n.rank-1,s=n.shape[t];(0,a.a)(n.rank>=2,(()=>`Error in grayscaleToRGB: images must be at least rank 2, but got rank ${n.rank}.`)),(0,a.a)(1===s,(()=>`Error in grayscaleToRGB: last dimension of a grayscale image should be size 1, but got size ${s}.`));const o=new Array(n.rank);return o.fill(1,0,t),o[t]=3,se(n,o)}}),Un=(0,r.o)({rotateWithOffset_:function(e,n,t=0,s=.5){const o=(0,r.q)(e,"image","rotateWithOffset","float32");(0,a.a)(4===o.rank,(()=>`Error in rotateWithOffset: image must be rank 4,but got rank ${o.rank}.`));const i={image:o},u={radians:n,fillValue:t,center:s};return r.E.runKernel(r.bE,i,u)}});function Yn(e,n,t,r,s,o){null==r&&(r=.5),null==s&&(s=Number.NEGATIVE_INFINITY),null==o&&(o=0);const i=e.shape[0];return t=Math.min(t,i),(0,a.a)(0<=r&&r<=1,(()=>`iouThreshold must be in [0, 1], but was '${r}'`)),(0,a.a)(2===e.rank,(()=>`boxes must be a 2D tensor, but was of rank '${e.rank}'`)),(0,a.a)(4===e.shape[1],(()=>`boxes must have 4 columns, but 2nd dimension was ${e.shape[1]}`)),(0,a.a)(1===n.rank,(()=>"scores must be a 1D tensor")),(0,a.a)(n.shape[0]===i,(()=>`scores has incompatible shape with boxes. Expected ${i}, but was ${n.shape[0]}`)),(0,a.a)(0<=o&&o<=1,(()=>`softNmsSigma must be in [0, 1], but was '${o}'`)),{maxOutputSize:t,iouThreshold:r,scoreThreshold:s,softNmsSigma:o}}const Zn=(0,r.o)({nonMaxSuppression_:function(e,n,t,a=.5,s=Number.NEGATIVE_INFINITY){const o=(0,r.q)(e,"boxes","nonMaxSuppression","float32"),i=(0,r.q)(n,"scores","nonMaxSuppression","float32"),u=Yn(o,i,t,a,s),l={maxOutputSize:t=u.maxOutputSize,iouThreshold:a=u.iouThreshold,scoreThreshold:s=u.scoreThreshold};return r.E.runKernel(r.bF,{boxes:o,scores:i},l)}}),Qn=(0,r.o)({nonMaxSuppressionWithScore_:function(e,n,t,a=.5,s=Number.NEGATIVE_INFINITY,o=0){const i=(0,r.q)(e,"boxes","nonMaxSuppression"),u=(0,r.q)(n,"scores","nonMaxSuppression"),l=Yn(i,u,t,a,s,o),h={boxes:i,scores:u},c={maxOutputSize:t=l.maxOutputSize,iouThreshold:a=l.iouThreshold,scoreThreshold:s=l.scoreThreshold,softNmsSigma:o=l.softNmsSigma},p=r.E.runKernel(r.bG,h,c);return{selectedIndices:p[0],selectedScores:p[1]}}}),jn=(0,r.o)({nonMaxSuppressionPadded_:function(e,n,t,a=.5,s=Number.NEGATIVE_INFINITY,o=!1){const i=(0,r.q)(e,"boxes","nonMaxSuppression"),u=(0,r.q)(n,"scores","nonMaxSuppression"),l=Yn(i,u,t,a,s,null),h={boxes:i,scores:u},c={maxOutputSize:l.maxOutputSize,iouThreshold:l.iouThreshold,scoreThreshold:l.scoreThreshold,padToMaxOutputSize:o},p=r.E.runKernel(r.bH,h,c);return{selectedIndices:p[0],validOutputs:p[1]}}}),Jn=(0,r.o)({resizeBilinear_:function(e,n,t=!1,s=!1){const o=(0,r.q)(e,"images","resizeBilinear");(0,a.a)(3===o.rank||4===o.rank,(()=>`Error in resizeBilinear: x must be rank 3 or 4, but got rank ${o.rank}.`)),(0,a.a)(2===n.length,(()=>`Error in resizeBilinear: new shape must 2D, but got shape ${n}.`)),(0,a.a)(!1===s||!1===t,(()=>"Error in resizeBilinear: If halfPixelCenters is true, alignCorners must be false."));let i=o,u=!1;3===o.rank&&(u=!0,i=(0,r.r)(o,[1,o.shape[0],o.shape[1],o.shape[2]]));const l={images:i},h={alignCorners:t,halfPixelCenters:s,size:n},c=r.E.runKernel(r.bI,l,h);return u?(0,r.r)(c,[c.shape[1],c.shape[2],c.shape[3]]):c}}),Xn=(0,r.o)({resizeNearestNeighbor_:function(e,n,t=!1,s=!1){const o=(0,r.q)(e,"images","resizeNearestNeighbor");(0,a.a)(3===o.rank||4===o.rank,(()=>`Error in resizeNearestNeighbor: x must be rank 3 or 4, but got rank ${o.rank}.`)),(0,a.a)(2===n.length,(()=>`Error in resizeNearestNeighbor: new shape must 2D, but got shape ${n}.`)),(0,a.a)("float32"===o.dtype||"int32"===o.dtype,(()=>"`images` must have `int32` or `float32` as dtype")),(0,a.a)(!1===s||!1===t,(()=>"Error in resizeNearestNeighbor: If halfPixelCenters is true, alignCorners must be false."));let i=o,u=!1;3===o.rank&&(u=!0,i=(0,r.r)(o,[1,o.shape[0],o.shape[1],o.shape[2]]));const l={images:i},h={alignCorners:t,halfPixelCenters:s,size:n},c=r.E.runKernel(r.bJ,l,h);return u?(0,r.r)(c,[c.shape[1],c.shape[2],c.shape[3]]):c}}),et=(0,r.o)({threshold_:function(e,n="binary",t=!1,s=.5){const o=(0,r.q)(e,"image","threshold"),i=o.shape[0]*o.shape[1];let u,l,c,d,f=(0,r.m)(wn([s]),255);if((0,a.a)(3===o.rank,(()=>`Error in threshold: image must be rank 3,but got rank ${o.rank}.`)),(0,a.a)(3===o.shape[2]||1===o.shape[2],(()=>`Error in threshold: image color channel must be equal to 3 or 1but got ${o.shape[2]}.`)),(0,a.a)("int32"===o.dtype||"float32"===o.dtype,(()=>`Error in dtype: image dtype must be int32 or float32,but got dtype ${o.dtype}.`)),(0,a.a)("otsu"===n||"binary"===n,(()=>`Method must be binary or otsu, but was ${n}`)),3===o.shape[2]){[u,l,c]=mn(o,[1,1,1],-1);const e=(0,r.m)(u,.2989),n=(0,r.m)(l,.587),t=(0,r.m)(c,.114);d=h(h(e,n),t)}else d=e;"otsu"===n&&(f=function(e,n){let t,a,s,o,i,u,l=wn([-1]),c=wn([0]),d=wn([0]);for(let f=0;f<e.size-1;f++){t=K(e,0,f+1),a=K(e,f+1),i=p((0,r.h)(t),n),u=p((0,r.h)(a),n);const m=(0,r.h)((0,r.m)(t,Xe(0,t.size)));s=p(m,(0,r.h)(t));const b=ie(a.shape,t.size),g=h(Xe(0,a.size),b),E=(0,r.m)(a,g);o=p((0,r.h)(E),(0,r.h)(a));const k=$e(s,o),x=$e(s,o),q=(0,r.m)(i,u);d=(0,r.m)((0,r.m)(q,k),x);const _=he(d,c);c=j(_,d,c),l=j(_,wn([f]),l)}return l}(z((0,r.c)(rn(d),"int32"),(0,r.t)([]),256),i));const m=t?me(d,f):he(d,f);return(0,r.c)((0,r.m)(m,255),"int32")}}),nt=(0,r.o)({transform_:function(e,n,t="nearest",s="constant",o=0,i){const u=(0,r.q)(e,"image","transform","float32"),l=(0,r.q)(n,"transforms","transform","float32");(0,a.a)(4===u.rank,(()=>`Error in transform: image must be rank 4,but got rank ${u.rank}.`)),(0,a.a)(2===l.rank&&(l.shape[0]===u.shape[0]||1===l.shape[0])&&8===l.shape[1],(()=>"Error in transform: Input transform should be batch x 8 or 1 x 8")),(0,a.a)(null==i||2===i.length,(()=>`Error in transform: outputShape must be [height, width] or null, but got ${i}.`));const h={image:u,transforms:l},c={interpolation:t,fillMode:s,fillValue:o,outputShape:i};return r.E.runKernel(r.bK,h,c)}});function tt(e,n=!1){return r.E.tidy((()=>{(0,a.a)(2===e.shape.length,(()=>`qr2d() requires a 2D Tensor, but got a ${e.shape.length}D Tensor.`));const t=e.shape[0],s=e.shape[1];let u=oe(t),h=(0,r.a)(e);const c=vn([[1]],[1,1]);let d=(0,r.a)(c);const f=t>=s?s:t;for(let e=0;e<f;++e){const n=h,a=d,f=u;[d,h,u]=r.E.tidy((()=>{const n=K(h,[e,e],[t-e,1]),a=Dn(n),o=K(h,[e,e],[1,1]),f=j(he(o,0),vn([[-1]]),vn([[1]])),m=$e(o,(0,r.m)(f,a)),b=p(n,m);d=1===b.shape[0]?(0,r.a)(c):N([c,K(b,[1,0],[b.shape[0]-1,b.shape[1]])],0);const g=_e(p(i(f,m),a)),E=K(h,[e,0],[t-e,s]),k=(0,r.m)(g,d),x=l(d);if(0===e)h=$e(E,i(k,i(x,E)));else{const n=$e(E,i(k,i(x,E)));h=N([K(h,[0,0],[e,s]),n],0)}const q=l(k),_=K(u,[0,e],[t,u.shape[1]-e]);if(0===e)u=$e(_,i(i(_,d),q));else{const n=$e(_,i(i(_,d),q));u=N([K(u,[0,0],[t,e]),n],1)}return[d,h,u]})),(0,o.d)([n,a,f])}return!n&&t>s&&(u=K(u,[0,0],[t,s]),h=K(h,[0,0],[s,s])),[u,h]}))}var rt;(0,r.o)({bandPart_:function(e,n,t){(0,a.a)(n%1==0,(()=>`bandPart(): numLower must be an integer, got ${n}.`)),(0,a.a)(t%1==0,(()=>`bandPart(): numUpper must be an integer, got ${t}.`));const s=(0,r.q)(e,"a","bandPart");(0,a.a)(s.rank>=2,(()=>`bandPart(): Rank must be at least 2, got ${s.rank}.`));const i=s.shape,[u,l]=s.shape.slice(-2);if(!(n<=u))throw new Error(`bandPart(): numLower (${n}) must not be greater than the number of rows (${u}).`);if(!(t<=l))throw new Error(`bandPart(): numUpper (${t}) must not be greater than the number of columns (${l}).`);n<0&&(n=u),t<0&&(t=l);const h=(0,r.r)(Xe(0,u,1,"int32"),[-1,1]),c=Xe(0,l,1,"int32"),p=$e(h,c),d=Ne(me(p,(0,o.s)(+n,"int32")),ce(p,(0,o.s)(-t,"int32"))),f=(0,o.z)([u,l],s.dtype);return(0,r.r)(xn(Nn((0,r.r)(s,[-1,u,l])).map((e=>j(d,e,f)))),i)}}),(0,r.o)({gramSchmidt_:function(e){let n;if(Array.isArray(e)){n=!1,(0,a.a)(null!=e&&e.length>0,(()=>"Gram-Schmidt process: input must not be null, undefined, or empty"));const t=e[0].shape[0];for(let n=1;n<e.length;++n)(0,a.a)(e[n].shape[0]===t,(()=>`Gram-Schmidt: Non-unique lengths found in the input vectors: (${e[n].shape[0]} vs. ${t})`))}else n=!0,e=mn(e,e.shape[0],0).map((e=>kn(e,[0])));(0,a.a)(e.length<=e[0].shape[0],(()=>`Gram-Schmidt: Number of vectors (${e.length}) exceeds number of dimensions (${e[0].shape[0]}).`));const t=[],s=e;for(let n=0;n<e.length;++n)t.push(r.E.tidy((()=>{let e=s[n];if(n>0)for(let a=0;a<n;++a){const n=(0,r.m)((0,r.h)((0,r.m)(t[a],e)),t[a]);e=$e(e,n)}return p(e,Dn(e,"euclidean"))})));return n?xn(t,0):t}}),(0,r.o)({qr_:function(e,n=!1){if((0,a.a)(e.rank>=2,(()=>`qr() requires input tensor to have a rank >= 2, but got rank ${e.rank}`)),2===e.rank)return tt(e,n);{const t=e.shape.slice(0,e.shape.length-2).reduce(((e,n)=>e*n)),a=Nn((0,r.r)(e,[t,e.shape[e.shape.length-2],e.shape[e.shape.length-1]]),0),s=[],o=[];return a.forEach((e=>{const[t,r]=tt(e,n);s.push(t),o.push(r)})),[(0,r.r)(xn(s,0),e.shape),(0,r.r)(xn(o,0),e.shape)]}}}),function(e){e[e.NONE=0]="NONE",e[e.MEAN=1]="MEAN",e[e.SUM=2]="SUM",e[e.SUM_BY_NONZERO_WEIGHTS=3]="SUM_BY_NONZERO_WEIGHTS"}(rt||(rt={}));const at=(0,r.o)({computeWeightedLoss_:function(e,n,t=rt.SUM_BY_NONZERO_WEIGHTS){const a=(0,r.q)(e,"losses","computeWeightedLoss");let s=null;null!=n&&(s=(0,r.q)(n,"weights","computeWeightedLoss"));const i=null==s?a:(0,r.m)(a,s);if(t===rt.NONE)return i;if(t===rt.SUM)return(0,r.h)(i);if(t===rt.MEAN){if(null==s)return Ce(i);{const e=a.size/s.size,n=p((0,r.h)(i),(0,r.h)(s));return e>1?p(n,(0,o.s)(e)):n}}if(t===rt.SUM_BY_NONZERO_WEIGHTS){if(null==s)return p((0,r.h)(i),(0,o.s)(a.size));{const e=(0,r.m)(s,Ae(a.shape)),n=(0,r.c)((0,r.h)(Ve(e,(0,o.s)(0))),"float32");return p((0,r.h)(i),n)}}throw Error(`Unknown reduction: ${t}`)}});(0,r.o)({absoluteDifference_:function(e,n,t,s=rt.SUM_BY_NONZERO_WEIGHTS){const o=(0,r.q)(e,"labels","absoluteDifference"),i=(0,r.q)(n,"predictions","absoluteDifference");let u=null;null!=t&&(u=(0,r.q)(t,"weights","absoluteDifference")),(0,a.e)(o.shape,i.shape,"Error in absoluteDifference: ");const l=d($e(o,i));return at(l,u,s)}}),(0,r.o)({cosineDistance_:function(e,n,t,s,i=rt.SUM_BY_NONZERO_WEIGHTS){const u=(0,r.q)(e,"labels","cosineDistance"),l=(0,r.q)(n,"predictions","cosineDistance");let h=null;null!=s&&(h=(0,r.q)(s,"weights","cosineDistance")),(0,a.e)(u.shape,l.shape,"Error in cosineDistance: ");const c=(0,o.s)(1),p=$e(c,(0,r.h)((0,r.m)(u,l),t,!0));return at(p,h,i)}}),(0,r.o)({hingeLoss_:function(e,n,t,s=rt.SUM_BY_NONZERO_WEIGHTS){let i=(0,r.q)(e,"labels","hingeLoss");const u=(0,r.q)(n,"predictions","hingeLoss");let l=null;null!=t&&(l=(0,r.q)(t,"weights","hingeLoss")),(0,a.e)(i.shape,u.shape,"Error in hingeLoss: ");const h=(0,o.s)(1);i=$e((0,r.m)((0,o.s)(2),i),h);const c=(0,r.d)($e(h,(0,r.m)(i,u)));return at(c,l,s)}}),(0,r.o)({huberLoss_:function(e,n,t,s=1,i=rt.SUM_BY_NONZERO_WEIGHTS){const u=(0,r.q)(e,"labels","huberLoss"),l=(0,r.q)(n,"predictions","huberLoss");let c=null;null!=t&&(c=(0,r.q)(t,"weights","huberLoss")),(0,a.e)(u.shape,l.shape,"Error in huberLoss: ");const p=(0,o.s)(s),f=d($e(l,u)),m=Re(f,p),b=$e(f,m),g=h((0,r.m)((0,o.s)(.5),Oe(m)),(0,r.m)(p,b));return at(g,c,i)}}),(0,r.o)({logLoss_:function(e,n,t,s=1e-7,i=rt.SUM_BY_NONZERO_WEIGHTS){const u=(0,r.q)(e,"labels","logLoss"),l=(0,r.q)(n,"predictions","logLoss");let c=null;null!=t&&(c=(0,r.q)(t,"weights","logLoss")),(0,a.e)(u.shape,l.shape,"Error in logLoss: ");const p=(0,o.s)(1),d=(0,o.s)(s),f=_e((0,r.m)(u,Ee(h(l,d)))),m=(0,r.m)($e(p,u),Ee(h($e(p,l),d))),b=$e(f,m);return at(b,c,i)}}),(0,r.o)({meanSquaredError_:function(e,n,t,s=rt.SUM_BY_NONZERO_WEIGHTS){const o=(0,r.q)(e,"labels","meanSquaredError"),i=(0,r.q)(n,"predictions","meanSquaredError");let u=null;null!=t&&(u=(0,r.q)(t,"weights","meanSquaredError")),(0,a.e)(o.shape,i.shape,"Error in meanSquaredError: ");const l=En(o,i);return at(l,u,s)}}),(0,r.o)({sigmoidCrossEntropy_:function(e,n,t,s=0,i=rt.SUM_BY_NONZERO_WEIGHTS){let u=(0,r.q)(e,"multiClassLabels","sigmoidCrossEntropy");const l=(0,r.q)(n,"logits","sigmoidCrossEntropy");let c=null;if(null!=t&&(c=(0,r.q)(t,"weights","sigmoidCrossEntropy")),(0,a.e)(u.shape,l.shape,"Error in sigmoidCrossEntropy: "),s>0){const e=(0,o.s)(s),n=(0,o.s)(1),t=(0,o.s)(.5);u=h((0,r.m)(u,$e(n,e)),(0,r.m)(t,e))}const p=function(e,n){const t=(0,r.q)(e,"labels","sigmoidCrossEntropyWithLogits"),s=(0,r.q)(n,"logits","sigmoidCrossEntropyWithLogits");(0,a.e)(t.shape,s.shape,"Error in sigmoidCrossEntropyWithLogits: ");const o=(0,r.d)(s),i=(0,r.m)(s,t),u=ke(te(_e(d(s))));return h($e(o,i),u)}(u,l);return at(p,c,i)}}),(0,r.o)({softmaxCrossEntropy_:function(e,n,t,s=0,i=rt.SUM_BY_NONZERO_WEIGHTS){let u=(0,r.q)(e,"onehotLabels","softmaxCrossEntropy");const l=(0,r.q)(n,"logits","softmaxCrossEntropy");let c=null;if(null!=t&&(c=(0,r.q)(t,"weights","softmaxCrossEntropy")),(0,a.e)(u.shape,l.shape,"Error in softmaxCrossEntropy: "),s>0){const e=(0,o.s)(s),n=(0,o.s)(1),t=(0,o.s)(u.shape[1]);u=h((0,r.m)(u,$e(n,e)),p(e,t))}const d=function(e,n,t=-1){if(-1===t&&(t=n.rank-1),t!==n.rank-1)throw Error(`Softmax cross entropy along a non-last dimension is not yet supported. Labels / logits was rank ${n.rank} and dim was ${t}`);const a=qe(((e,n,a)=>{const s=Se(n,[t],!0),o=$e((0,r.c)(n,"float32"),s);a([e,o]);const i=_e((0,r.m)(o,e));return{value:(0,r.h)(i,[t]),gradFunc:(e,n)=>{const[a,s]=n,o=(0,r.aF)(e.shape,[t]);return[(0,r.m)((0,r.r)(e,o),$e((0,r.c)(a,"float32"),te(s))),(0,r.m)((0,r.r)(e,o),$e(te(s),(0,r.c)(a,"float32")))]}}}));return a(e,n)}(u,l);return at(d,c,i)}});const st=(0,r.o)({sparseFillEmptyRows_:function(e,n,t,a){const s=(0,r.q)(e,"indices","sparseFillEmptyRows","int32"),o=(0,r.q)(n,"values","sparseFillEmptyRows"),i=(0,r.q)(t,"denseShape","sparseFillEmptyRows","int32"),u=(0,r.q)(a,"defaultValue","sparseFillEmptyRows",o.dtype);if(2!==s.rank)throw new Error(`Indices should be Tensor2D but received shape\n        ${s.shape}`);if(1!==o.rank)throw new Error(`Values should be Tensor1D but received shape ${o.shape}`);if(1!==i.rank)throw new Error(`Dense shape should be Tensor1D but received shape ${i.shape}`);if(0!==u.rank)throw new Error(`Default value should be a scalar but received shape ${u.shape}`);const l={indices:s,values:o,denseShape:i,defaultValue:u},h=r.E.runKernel(r.bL,l);return{outputIndices:h[0],outputValues:h[1],emptyRowIndicator:h[2],reverseIndexMap:h[3]}}}),ot=(0,r.o)({sparseReshape_:function(e,n,t){const a=(0,r.q)(e,"inputIndices","sparseReshape","int32"),s=(0,r.q)(n,"inputShape","sparseReshape","int32"),o=(0,r.q)(t,"newShape","sparseReshape","int32");if(2!==a.rank)throw new Error(`Input indices should be Tensor2D but received shape\n        ${a.shape}`);if(1!==s.rank)throw new Error(`Input shape should be Tensor1D but received shape ${s.shape}`);if(1!==o.rank)throw new Error(`New shape should be Tensor1D but received shape ${o.shape}`);const i={inputIndices:a,inputShape:s,newShape:o},u=r.E.runKernel(r.bM,i);return{outputIndices:u[0],outputShape:u[1]}}}),it=(0,r.o)({sparseSegmentMean_:function(e,n,t){const a=(0,r.q)(e,"data","sparseSegmentMean"),s=(0,r.q)(n,"indices","sparseSegmentMean","int32"),o=(0,r.q)(t,"segmentIds","sparseSegmentMean","int32");if(a.rank<1)throw new Error("Data should be at least 1 dimensional but received scalar");if(1!==s.rank)throw new Error(`Indices should be Tensor1D but received shape\n          ${s.shape}`);if(1!==o.rank)throw new Error(`Segment ids should be Tensor1D but received shape\n          ${o.shape}`);const i={data:a,indices:s,segmentIds:o};return r.E.runKernel(r.bN,i)}}),ut=(0,r.o)({sparseSegmentSum_:function(e,n,t){const a=(0,r.q)(e,"data","sparseSegmentSum"),s=(0,r.q)(n,"indices","sparseSegmentSum","int32"),o=(0,r.q)(t,"segmentIds","sparseSegmentSum","int32");if(a.rank<1)throw new Error("Data should be at least 1 dimensional but received scalar");if(1!==s.rank)throw new Error(`Indices should be Tensor1D but received shape\n         ${s.shape}`);if(1!==o.rank)throw new Error(`Segment ids should be Tensor1D but received shape\n         ${o.shape}`);const i={data:a,indices:s,segmentIds:o};return r.E.runKernel(r.bO,i)}}),lt=(0,r.o)({stringNGrams_:function(e,n,t,a,s,o,i,u){const l=(0,r.q)(e,"data","stringNGrams","string");if("string"!==l.dtype)throw new Error("Data must be of datatype string");if(1!==l.shape.length)throw new Error(`Data must be a vector, saw: ${l.shape}`);const h=(0,r.q)(n,"dataSplits","stringNGrams");if("int32"!==h.dtype)throw new Error("Data splits must be of datatype int32");const c={separator:t,nGramWidths:a,leftPad:s,rightPad:o,padWidth:i,preserveShortSequences:u},p={data:l,dataSplits:h},d=r.E.runKernel(r.bP,p,c);return{nGrams:d[0],nGramsSplits:d[1]}}}),ht=(0,r.o)({stringSplit_:function(e,n,t=!0){const a=(0,r.q)(e,"input","stringSplit","string"),s=(0,r.q)(n,"delimiter","stringSplit","string");if(1!==a.rank)throw new Error(`Input should be Tensor1D but received shape ${a.shape}`);if(0!==s.rank)throw new Error(`Delimiter should be a scalar but received shape ${s.shape}`);const o={skipEmpty:t},i={input:a,delimiter:s},u=r.E.runKernel(r.bQ,i,o);return{indices:u[0],values:u[1],shape:u[2]}}}),ct=(0,r.o)({stringToHashBucketFast_:function(e,n){const t=(0,r.q)(e,"input","stringToHashBucketFast","string"),a={numBuckets:n};if(n<=0)throw new Error("Number of buckets must be at least 1");const s={input:t};return r.E.runKernel(r.bR,s,a)}}),pt={flipLeftRight:Gn,grayscaleToRGB:Ln,resizeNearestNeighbor:Xn,resizeBilinear:Jn,rotateWithOffset:Un,cropAndResize:Bn,nonMaxSuppression:Zn,nonMaxSuppressionAsync:async function(e,n,t,a=.5,s=Number.NEGATIVE_INFINITY){const i=(0,r.q)(e,"boxes","nonMaxSuppressionAsync"),u=(0,r.q)(n,"scores","nonMaxSuppressionAsync"),l=Yn(i,u,t,a,s);t=l.maxOutputSize,a=l.iouThreshold,s=l.scoreThreshold;const h=await Promise.all([i.data(),u.data()]),c=h[0],p=h[1],{selectedIndices:d}=(0,o.n)(c,p,t,a,s);return i!==e&&i.dispose(),u!==n&&u.dispose(),wn(d,"int32")},nonMaxSuppressionWithScore:Qn,nonMaxSuppressionWithScoreAsync:async function(e,n,t,a=.5,s=Number.NEGATIVE_INFINITY,i=0){const u=(0,r.q)(e,"boxes","nonMaxSuppressionAsync"),l=(0,r.q)(n,"scores","nonMaxSuppressionAsync"),h=Yn(u,l,t,a,s,i);t=h.maxOutputSize,a=h.iouThreshold,s=h.scoreThreshold,i=h.softNmsSigma;const c=await Promise.all([u.data(),l.data()]),p=c[0],d=c[1],{selectedIndices:f,selectedScores:m}=(0,o.a)(p,d,t,a,s,i);return u!==e&&u.dispose(),l!==n&&l.dispose(),{selectedIndices:wn(f,"int32"),selectedScores:wn(m)}},nonMaxSuppressionPadded:jn,nonMaxSuppressionPaddedAsync:async function(e,n,t,a=.5,s=Number.NEGATIVE_INFINITY,i=!1){const u=(0,r.q)(e,"boxes","nonMaxSuppressionAsync"),l=(0,r.q)(n,"scores","nonMaxSuppressionAsync"),h=Yn(u,l,t,a,s,null),c=h.maxOutputSize,p=h.iouThreshold,d=h.scoreThreshold,[f,m]=await Promise.all([u.data(),l.data()]),{selectedIndices:b,validOutputs:g}=(0,o.b)(f,m,c,p,d,i);return u!==e&&u.dispose(),l!==n&&l.dispose(),{selectedIndices:wn(b,"int32"),validOutputs:(0,o.s)(g,"int32")}},threshold:et,transform:nt},dt={sparseFillEmptyRows:st,sparseReshape:ot,sparseSegmentMean:it,sparseSegmentSum:ut},ft={stringNGrams:lt,stringSplit:ht,stringToHashBucketFast:ct}}}]);